# ğŸ“‹ Sistema de Logs Detallados

## Â¿QuÃ© es?

Sistema de logging completo que registra **TODO** el proceso de generaciÃ³n de prÃ¡cticas en archivos individuales por consulta.

## ğŸ“ UbicaciÃ³n de los Logs

Los logs se guardan automÃ¡ticamente en:
```
logs_practicas_detallado/
â”œâ”€â”€ practica_20251119_143052.log    (archivo legible)
â”œâ”€â”€ practica_20251119_143052.json   (formato JSON)
â”œâ”€â”€ practica_20251119_143210.log
â”œâ”€â”€ practica_20251119_143210.json
â””â”€â”€ ...
```

Cada generaciÃ³n de prÃ¡ctica crea **2 archivos**:
- `.log` â†’ Formato legible para humanos
- `.json` â†’ Formato estructurado para anÃ¡lisis

## ğŸ“Š Contenido del Log

Cada archivo `.log` contiene **7 secciones completas**:

### 1. REQUEST RECIBIDO DEL FRONTEND
```
num_preguntas: {'true_false': 2}
ajustes_modelo: {'temperature': 0.7, 'max_tokens': 4000}
sin_prompt_sistema: True
usar_ollama: True
modelo: qwen-local:latest
contenido_length: 2163
```

### 2. PROMPT ENVIADO AL MODELO
```
Longitud: 2163 caracteres

Genera una prÃ¡ctica educativa basada en el contenido proporcionado.

TIPOS DE PREGUNTAS A GENERAR:

**2 Verdadero/Falso** - Formato JSON:
{
  "type": "true_false",
  ...
}
```

### 3. RESPUESTA COMPLETA DEL MODELO
```
Longitud: 4316 caracteres

[Respuesta completa sin modificar del modelo de IA]
```

### 4. JSON EXTRAÃDO Y PARSEADO
```json
{
  "questions": [
    {
      "type": "true_false",
      "difficulty": "medium",
      "statement": "Un diseÃ±o visualmente atractivo...",
      "correct_answer": true,
      "explanation": "..."
    }
  ]
}
```

### 5. PREGUNTAS PARSEADAS (Objetos Python)
```json
Pregunta 1:
{
  "tipo": "true_false",
  "pregunta": "Un diseÃ±o visualmente atractivo...",
  "respuesta_correcta": true,
  "puntos": 1,
  "dificultad": "medium"
}
```

### 6. PROCESO DE FILTRADO
```
total_generadas: 2
total_filtradas: 2
solicitadas: {'true_false': 2}
contador_por_tipo: {'true_false': 2}
```

### 7. RESULTADO FINAL DEVUELTO AL FRONTEND
```json
Total preguntas: 2

Pregunta 1:
{
  "tipo": "true_false",
  "pregunta": "...",
  ...
}

Pregunta 2:
{
  "tipo": "true_false",
  "pregunta": "...",
  ...
}
```

### 8. ERRORES ENCONTRADOS (si los hay)
```
â€¢ El modelo no generÃ³ suficientes preguntas: true_false: 1/2
â€¢ Error parseando JSON: Unexpected character at position 123
```

## ğŸ” CÃ³mo Usar los Logs

### Verificar en la Terminal
Cuando generas una prÃ¡ctica, verÃ¡s en la terminal:
```
ğŸ“‹ Log detallado: logs_practicas_detallado\practica_20251119_143052.log
```

### Leer el Archivo
1. Abre el archivo `.log` con cualquier editor de texto
2. Busca la secciÃ³n que te interesa (estÃ¡n numeradas)
3. Compara lo que enviaste vs lo que recibiste vs lo que se pintÃ³

### Identificar Problemas

**Problema: No se generaron preguntas**
1. Ve a **SecciÃ³n 3** (Respuesta del modelo)
   - Â¿El modelo respondiÃ³ algo?
   - Â¿EstÃ¡ en formato JSON?

2. Ve a **SecciÃ³n 4** (JSON extraÃ­do)
   - Â¿Se pudo extraer el JSON?
   - Â¿Tiene el campo `questions`?

3. Ve a **SecciÃ³n 8** (Errores)
   - Â¿QuÃ© error especÃ­fico ocurriÃ³?

**Problema: Se generaron menos preguntas de las solicitadas**
1. Ve a **SecciÃ³n 6** (Filtrado)
   - `solicitadas`: Â¿QuÃ© pediste?
   - `contador_por_tipo`: Â¿QuÃ© generÃ³ el modelo?
   - Si no coinciden â†’ el modelo generÃ³ tipos diferentes

2. Ve a **SecciÃ³n 5** (Preguntas parseadas)
   - Verifica el `tipo` de cada pregunta
   - Compara con lo que solicitaste en SecciÃ³n 1

**Problema: Preguntas incorrectas o raras**
1. Ve a **SecciÃ³n 2** (Prompt enviado)
   - Â¿Las instrucciones son claras?
   - Â¿El contenido es suficiente?

2. Ve a **SecciÃ³n 3** (Respuesta del modelo)
   - Â¿El modelo entendiÃ³ las instrucciones?
   - Â¿AgregÃ³ texto extra fuera del JSON?

## ğŸ“ˆ AnÃ¡lisis de Patrones

Si tienes mÃºltiples logs, puedes:

1. **Buscar patrones de error**:
   ```powershell
   Get-ChildItem logs_practicas_detallado\*.log | Select-String "Error"
   ```

2. **Ver cuÃ¡ntas preguntas se generaron por log**:
   ```powershell
   Get-ChildItem logs_practicas_detallado\*.log | Select-String "Total preguntas:"
   ```

3. **Encontrar casos donde el filtrado redujo preguntas**:
   ```powershell
   Get-ChildItem logs_practicas_detallado\*.log | Select-String "generadas â†’"
   ```

## ğŸ¯ Casos de Uso

### 1. Reportar un Bug
Cuando encuentres un problema:
1. Genera la prÃ¡ctica problemÃ¡tica
2. Copia el nombre del archivo log que aparece en terminal
3. Comparte ese archivo con el desarrollador
4. El desarrollador verÃ¡ **exactamente** quÃ© pasÃ³ en cada paso

### 2. Entender por quÃ© el modelo falla
Si el modelo constantemente genera tipos incorrectos:
1. Revisa **SecciÃ³n 2** de varios logs
2. Compara los prompts
3. Verifica si hay patrones en **SecciÃ³n 3** (respuestas)

### 3. Optimizar el contenido
Si las preguntas son malas:
1. Ve a **SecciÃ³n 2** â†’ largo del contenido
2. Si es muy corto (< 500 chars) â†’ el modelo no tiene suficiente info
3. Si es muy largo (> 8000 chars) â†’ se trunca

## âš™ï¸ ConfiguraciÃ³n

El sistema de logging estÃ¡ **siempre activo** y se ejecuta automÃ¡ticamente cada vez que:
- Generas una nueva prÃ¡ctica desde el frontend
- El backend llama a `generador_actual.generar_examen()`

**No necesitas hacer nada**, los logs se crean solos.

## ğŸ—‘ï¸ Limpieza

Para limpiar logs antiguos:
```powershell
# Eliminar logs de mÃ¡s de 7 dÃ­as
Get-ChildItem logs_practicas_detallado\* -File | 
  Where-Object {$_.LastWriteTime -lt (Get-Date).AddDays(-7)} | 
  Remove-Item
```

## ğŸ†˜ Soporte

Si encuentras problemas:
1. Localiza el archivo `.log` de la consulta problemÃ¡tica
2. Revisa las 7 secciones en orden
3. Identifica en quÃ© secciÃ³n ocurre el problema
4. Comparte esa informaciÃ³n especÃ­fica

Los logs te darÃ¡n **visibilidad completa** de todo el proceso de generaciÃ³n. ğŸ”
