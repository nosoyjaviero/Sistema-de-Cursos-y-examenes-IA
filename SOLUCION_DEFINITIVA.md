# üéØ SOLUCI√ìN DEFINITIVA: Instalar integraci√≥n CUDA con Visual Studio

## El Problema Real

CMake busca archivos espec√≠ficos de integraci√≥n CUDA que **NO est√°n instalados**:
```
C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\MSBuild\Microsoft\VC\v170\BuildCustomizations\CUDA 12.2.props
```

Estos archivos se instalan cuando:
1. Instalas CUDA Toolkit **DESPU√âS** de Visual Studio, O
2. Seleccionas "Visual Studio Integration" durante instalaci√≥n de CUDA

## ‚úÖ SOLUCI√ìN (15 minutos)

### Opci√≥n A: Reinstalar CUDA con integraci√≥n VS

1. **Descargar CUDA 12.2**:
   - https://developer.nvidia.com/cuda-12-2-0-download-archive
   - Seleccionar: Windows > x86_64 > 10/11 > exe (network)

2. **Ejecutar instalador**:
   - **IMPORTANTE**: Seleccionar "Custom (Advanced)"
   - Marcar: ‚úÖ **Visual Studio Integration**
   - Marcar: ‚úÖ **Development**
   - Marcar: ‚úÖ **Runtime**
   - Siguiente ‚Üí Instalar

3. **Verificar instalaci√≥n**:
   ```powershell
   Test-Path "C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\MSBuild\Microsoft\VC\v170\BuildCustomizations\CUDA 12.2.props"
   ```
   Debe devolver: `True`

4. **Compilar llama-cpp-python**:
   ```powershell
   .\instalar_llama_cuda_avanzado.ps1
   ```

### Opci√≥n B: Copiar archivos manualmente (m√°s r√°pido)

Si ya tienes CUDA instalado, solo faltan los archivos de integraci√≥n:

1. **Descargar solo el instalador** (no ejecutar instalaci√≥n completa)
2. **Extraer archivos**:
   ```powershell
   # Los instaladores CUDA son archivos 7z
   # Extraer en carpeta temporal
   ```
3. **Copiar archivos de integraci√≥n**:
   ```
   Desde: CUDAVisualStudioIntegration\extras\visual_studio_integration\MSBuildExtensions\
   Hacia: C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\MSBuild\Microsoft\VC\v170\BuildCustomizations\
   ```
   Archivos necesarios:
   - CUDA 12.2.props
   - CUDA 12.2.targets
   - CUDA 12.2.xml
   - Nvda.Build.CudaTasks.v12.2.dll

### Opci√≥n C: Usar binarios precompilados de llama.cpp (RECOMENDADO)

**La forma M√ÅS R√ÅPIDA de tener GPU funcionando AHORA**:

1. **Descargar llama.cpp con CUDA**:
   - https://github.com/ggerganov/llama.cpp/releases/latest
   - Buscar: `llama-*-bin-win-cuda-cu12.2.0-x64.zip`
   - Descargar y extraer

2. **Ejecutar servidor**:
   ```powershell
   cd llama-cpp-extracted
   .\llama-server.exe --model "C:\Users\Fela\Documents\Proyectos\Examinator\modelos\qwen2.5-3b-instruct-q4_k_m.gguf" --n-gpu-layers 35 --port 8080 --host 0.0.0.0
   ```

3. **Modificar tu c√≥digo para usar el servidor**:
   - En lugar de cargar modelo con Llama()
   - Hacer peticiones HTTP a http://localhost:8080/completion

**Ventajas**:
- ‚úÖ GPU funciona inmediatamente
- ‚úÖ No requiere compilaci√≥n
- ‚úÖ Mismo rendimiento
- ‚úÖ Mismo formato de modelo (.gguf)

## üöÄ Mi Recomendaci√≥n Final

**AHORA MISMO** (2 minutos):
1. Descarga binarios precompilados de llama.cpp
2. Ejecuta llama-server.exe con --n-gpu-layers 35
3. GPU funcionar√° inmediatamente

**DESPU√âS** (si quieres):
1. Reinstala CUDA con Visual Studio Integration
2. Compila llama-cpp-python
3. Integra directamente en tu c√≥digo

## üì¶ Script para usar binarios precompilados

Voy a crear un adaptador para que uses llama-server.exe con tu c√≥digo actual:

```python
# generador_llama_server.py
import requests
from typing import List, Dict
from generador_dos_pasos import PreguntaExamen

class GeneradorLlamaServer:
    def __init__(self, server_url: str = "http://localhost:8080"):
        self.server_url = server_url
    
    def _generate(self, prompt: str, temperature: float, max_tokens: int):
        response = requests.post(
            f"{self.server_url}/completion",
            json={
                "prompt": prompt,
                "temperature": temperature,
                "n_predict": max_tokens,
                "stop": ["<|eot_id|>", "<|end_of_text|>"]
            }
        )
        return response.json()["content"]
    
    # Resto igual que GeneradorDosPasos
    # Solo cambia self.llm() por self._generate()
```

¬øQuieres que:
1. Reinstalemos CUDA con integraci√≥n VS?
2. Usemos binarios precompilados (m√°s r√°pido)?
3. Probemos Ollama (m√°s simple)?
