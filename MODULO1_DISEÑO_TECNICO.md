# üîç M√ìDULO 1: Detector de Errores - Dise√±o T√©cnico

## üìã Resumen Ejecutivo

Este documento describe el dise√±o del **M√≥dulo 1: Detector de Errores por Pregunta**, primer componente del sistema de an√°lisis de patrones de error para Examinator.

**Objetivo:** Clasificar autom√°ticamente cada pregunta de ex√°menes completados en `acierto`, `fallo` o `respuesta_debil` para an√°lisis posterior.

---

## üéØ Requisitos Funcionales

### RF-1: Lectura de Ex√°menes Completados
- Leer archivos JSON de `examenes/{carpeta}/`
- Validar que sean ex√°menes tipo `"completado"`
- Mantener compatibilidad con estructura existente

### RF-2: Clasificaci√≥n por Tipo de Pregunta

#### Preguntas Objetivas (`multiple`, `verdadero_falso`, `flashcard`)
- **M√©todo primario:** Comparaci√≥n directa `respuesta_usuario == respuesta_correcta`
- **M√©todo fallback:** Ratio de puntos (cuando `respuesta_correcta` es `null`)

#### Preguntas Subjetivas (`corta`, `desarrollo`)
- **M√©todo:** Ratio `puntos / puntos_maximos`
- **Umbrales:**
  - `< 0.7` ‚Üí `fallo`
  - `0.7 - 0.89` ‚Üí `respuesta_debil`
  - `‚â• 0.9` ‚Üí `acierto`

### RF-3: Estructura de Salida
Cada pregunta debe incluir:
```python
{
  "id_pregunta": str | None,          # Identificador √∫nico (puede no existir)
  "tipo": str,                        # multiple | verdadero_falso | flashcard | corta | desarrollo
  "pregunta": str,                    # Texto de la pregunta
  "respuesta_usuario": any,           # Respuesta dada por el usuario
  "respuesta_correcta": any | None,   # Respuesta correcta (null en subjetivas)
  "puntos": float,                    # Puntos obtenidos
  "puntos_maximos": float,            # Puntos m√°ximos posibles
  "feedback": str,                    # Retroalimentaci√≥n de la IA
  "estado_respuesta": str             # ‚Üê NUEVO: "acierto" | "fallo" | "respuesta_debil"
}
```

### RF-4: No Romper Sistema Existente
- **No modificar** archivos JSON originales de ex√°menes
- **No interferir** con flujos actuales de generaci√≥n/evaluaci√≥n
- **Operar como m√≥dulo independiente** de an√°lisis

---

## üèóÔ∏è Arquitectura del M√≥dulo

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  DETECTOR DE ERRORES                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ  DetectorErrores (Clase Principal)             ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ analizar_examen(ruta_json)                 ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ analizar_multiples_examenes([rutas])       ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ filtrar_por_estado(resultados, estado)     ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ generar_reporte_texto(analisis)            ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                       ‚Üì                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ  ResultadoPreguntaExtendido (Modelo de Datos)  ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Campos originales del examen               ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ estado_respuesta (NUEVO)                   ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ _clasificar_respuesta() ‚Üí EstadoRespuesta  ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ  JSON Examen         ‚îÇ
            ‚îÇ  examenes/.../       ‚îÇ
            ‚îÇ  examen_xxx.json     ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Algoritmo de Clasificaci√≥n

### Pseudoc√≥digo

```python
funci√≥n clasificar_respuesta(pregunta):
    ratio = pregunta.puntos / pregunta.puntos_maximos
    
    SI pregunta.tipo EN ["multiple", "verdadero_falso", "flashcard"]:
        # Preguntas objetivas
        
        SI pregunta.respuesta_correcta NO ES null:
            # Comparaci√≥n directa
            SI normalizar(pregunta.respuesta_usuario) == normalizar(pregunta.respuesta_correcta):
                RETORNAR "acierto"
            SINO:
                RETORNAR "fallo"
        SINO:
            # Fallback a ratio (flashcards evaluadas por IA)
            SI ratio >= 0.9:
                RETORNAR "acierto"
            SINO SI ratio >= 0.7:
                RETORNAR "respuesta_debil"
            SINO:
                RETORNAR "fallo"
    
    SINO SI pregunta.tipo EN ["corta", "desarrollo"]:
        # Preguntas subjetivas
        SI ratio >= 0.9:
            RETORNAR "acierto"
        SINO SI ratio >= 0.7:
            RETORNAR "respuesta_debil"
        SINO:
            RETORNAR "fallo"
    
    SINO:
        # Tipo desconocido: usar ratio conservador
        SI ratio >= 0.9:
            RETORNAR "acierto"
        SINO SI ratio >= 0.7:
            RETORNAR "respuesta_debil"
        SINO:
            RETORNAR "fallo"
```

### Ejemplo de Aplicaci√≥n

#### Caso 1: Pregunta de Opci√≥n M√∫ltiple
```json
{
  "tipo": "multiple",
  "respuesta_usuario": "B",
  "respuesta_correcta": "A",
  "puntos": 0,
  "puntos_maximos": 3
}
```
**Clasificaci√≥n:** `fallo` (comparaci√≥n directa: B ‚â† A)

#### Caso 2: Pregunta de Desarrollo
```json
{
  "tipo": "desarrollo",
  "respuesta_usuario": "El dise√±o influye en la percepci√≥n...",
  "respuesta_correcta": null,
  "puntos": 2.5,
  "puntos_maximos": 3
}
```
**Clasificaci√≥n:** `respuesta_debil` (ratio: 2.5/3 = 0.833, que est√° en [0.7, 0.89])

#### Caso 3: Flashcard Evaluada por IA
```json
{
  "tipo": "flashcard",
  "respuesta_usuario": "Relaci√≥n y jerarqu√≠a",
  "respuesta_correcta": null,
  "puntos": 0.5,
  "puntos_maximos": 1
}
```
**Clasificaci√≥n:** `fallo` (ratio: 0.5/1 = 0.5, que es < 0.7)

---

## üîå API del M√≥dulo

### Clase `DetectorErrores`

#### `analizar_examen(ruta_json: str) -> Dict`

Analiza un examen completado y retorna an√°lisis completo.

**Par√°metros:**
- `ruta_json`: Ruta al JSON del examen (ej: `"examenes/Platzi/examen_20251120_134728.json"`)

**Retorna:**
```python
{
  "metadata": {
    "id": str,
    "carpeta": str,
    "carpeta_ruta": str,
    "fecha_completado": str,
    "puntos_obtenidos": float,
    "puntos_totales": float,
    "porcentaje": float
  },
  "resultados_clasificados": [
    {
      # Campos originales + estado_respuesta
      "estado_respuesta": "acierto" | "fallo" | "respuesta_debil"
    }
  ],
  "resumen_estados": {
    "total_preguntas": int,
    "aciertos": int,
    "fallos": int,
    "respuestas_debiles": int,
    "porcentaje_aciertos": float,
    "porcentaje_fallos": float,
    "porcentaje_debiles": float
  }
}
```

**Excepciones:**
- `FileNotFoundError`: Archivo no existe
- `json.JSONDecodeError`: JSON malformado
- `KeyError`: Faltan campos requeridos
- `ValueError`: Examen no completado

**Ejemplo de uso:**
```python
detector = DetectorErrores()
analisis = detector.analizar_examen("examenes/Platzi/examen_20251120_134728.json")

print(f"Fallos: {analisis['resumen_estados']['fallos']}")
```

---

#### `analizar_multiples_examenes(rutas_json: List[str]) -> List[Dict]`

Analiza m√∫ltiples ex√°menes en batch.

**Par√°metros:**
- `rutas_json`: Lista de rutas a archivos JSON

**Retorna:**
- Lista de diccionarios de an√°lisis (mismo formato que `analizar_examen()`)

**Manejo de errores:**
- Errores individuales se imprimen y se omite el examen problem√°tico
- Contin√∫a con los dem√°s ex√°menes

**Ejemplo:**
```python
rutas = [
    "examenes/Platzi/examen_20251120_134728.json",
    "examenes/Platzi/examen_20251120_133845.json"
]

resultados = detector.analizar_multiples_examenes(rutas)
print(f"Se analizaron {len(resultados)} ex√°menes")
```

---

#### `filtrar_por_estado(resultados_clasificados: List[Dict], estado: EstadoRespuesta) -> List[Dict]`

Filtra preguntas por estado de respuesta.

**Par√°metros:**
- `resultados_clasificados`: Lista de preguntas del an√°lisis
- `estado`: `"acierto"` | `"fallo"` | `"respuesta_debil"`

**Retorna:**
- Lista filtrada de preguntas

**Ejemplo:**
```python
analisis = detector.analizar_examen("examenes/Platzi/examen_20251120_134728.json")

# Obtener solo los fallos
fallos = detector.filtrar_por_estado(
    analisis["resultados_clasificados"], 
    "fallo"
)

print(f"Preguntas falladas: {len(fallos)}")
for fallo in fallos:
    print(f"- {fallo['pregunta'][:50]}...")
```

---

#### `generar_reporte_texto(analisis: Dict) -> str`

Genera reporte formateado en texto plano.

**Par√°metros:**
- `analisis`: Resultado de `analizar_examen()`

**Retorna:**
- String con reporte formateado con emojis y tablas ASCII

**Ejemplo:**
```python
analisis = detector.analizar_examen("examenes/Platzi/examen_20251120_134728.json")
reporte = detector.generar_reporte_texto(analisis)

print(reporte)
# O guardar en archivo
with open("reporte.txt", "w", encoding="utf-8") as f:
    f.write(reporte)
```

---

### Clase `ResultadoPreguntaExtendido`

Modelo de datos para una pregunta clasificada.

**Atributos p√∫blicos:**
- `id_pregunta: str | None`
- `pregunta: str`
- `tipo: str`
- `opciones: List[str]`
- `respuesta_usuario: any`
- `respuesta_correcta: any | None`
- `puntos: float`
- `puntos_maximos: float`
- `feedback: str`
- `estado_respuesta: EstadoRespuesta` ‚Üê **NUEVO**

**M√©todos:**
- `to_dict() -> Dict`: Convierte a diccionario

**Uso:**
```python
pregunta_data = {
    "pregunta": "¬øQu√© es Python?",
    "tipo": "corta",
    "puntos": 2.5,
    "puntos_maximos": 3,
    ...
}

pregunta = ResultadoPreguntaExtendido(pregunta_data)
print(pregunta.estado_respuesta)  # "respuesta_debil"
```

---

## üìÅ Estructura de Archivos

```
Examinator/
‚îú‚îÄ‚îÄ detector_errores.py              # ‚Üê NUEVO: M√≥dulo principal
‚îú‚îÄ‚îÄ MODULO1_DISE√ëO_TECNICO.md        # ‚Üê NUEVO: Este documento
‚îú‚îÄ‚îÄ test_detector_errores.py         # ‚Üê NUEVO: Tests unitarios (pr√≥ximo paso)
‚îÇ
‚îú‚îÄ‚îÄ api_server.py                    # Sin modificar
‚îú‚îÄ‚îÄ generador_unificado.py           # Sin modificar
‚îú‚îÄ‚îÄ examinator.py                    # Sin modificar
‚îú‚îÄ‚îÄ ...                              # Resto del sistema intacto
‚îÇ
‚îî‚îÄ‚îÄ examenes/                        # Datos de entrada (sin modificar)
    ‚îú‚îÄ‚îÄ Platzi/
    ‚îÇ   ‚îú‚îÄ‚îÄ examen_20251120_134728.json
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ .../
```

---

## üß™ Casos de Prueba

### Test 1: Pregunta M√∫ltiple Correcta
```python
{
  "tipo": "multiple",
  "respuesta_usuario": "A",
  "respuesta_correcta": "A",
  "puntos": 3,
  "puntos_maximos": 3
}
```
**Esperado:** `"acierto"`

### Test 2: Pregunta M√∫ltiple Incorrecta
```python
{
  "tipo": "multiple",
  "respuesta_usuario": "B",
  "respuesta_correcta": "A",
  "puntos": 0,
  "puntos_maximos": 3
}
```
**Esperado:** `"fallo"`

### Test 3: Verdadero/Falso con respuesta_correcta null
```python
{
  "tipo": "verdadero_falso",
  "respuesta_usuario": "falso",
  "respuesta_correcta": null,
  "puntos": 2,
  "puntos_maximos": 2
}
```
**Esperado:** `"acierto"` (ratio: 2/2 = 1.0 >= 0.9)

### Test 4: Desarrollo - Respuesta Parcial
```python
{
  "tipo": "desarrollo",
  "puntos": 2.5,
  "puntos_maximos": 3
}
```
**Esperado:** `"respuesta_debil"` (ratio: 0.833 est√° en [0.7, 0.89])

### Test 5: Corta - Fallo
```python
{
  "tipo": "corta",
  "puntos": 0.5,
  "puntos_maximos": 3
}
```
**Esperado:** `"fallo"` (ratio: 0.166 < 0.7)

### Test 6: Flashcard - Respuesta D√©bil
```python
{
  "tipo": "flashcard",
  "respuesta_correcta": null,
  "puntos": 0.8,
  "puntos_maximos": 1
}
```
**Esperado:** `"respuesta_debil"` (ratio: 0.8 est√° en [0.7, 0.89])

### Test 7: Caso Borde - Puntos M√°ximos = 0
```python
{
  "tipo": "multiple",
  "puntos": 0,
  "puntos_maximos": 0
}
```
**Esperado:** `"fallo"` (ratio: 0 < 0.7)

---

## ‚ö†Ô∏è Consideraciones Especiales

### 1. Normalizaci√≥n de Respuestas
Para preguntas objetivas con comparaci√≥n directa:
```python
resp_usuario = str(respuesta_usuario).strip().lower()
resp_correcta = str(respuesta_correcta).strip().lower()
```
Evita falsos negativos por espacios/may√∫sculas.

### 2. Manejo de respuesta_correcta = null
- Com√∫n en: `flashcard`, `verdadero_falso`, `corta`, `desarrollo`
- Raz√≥n: Evaluadas por IA, no tienen "respuesta exacta"
- Soluci√≥n: Usar ratio de puntos

### 3. Compatibilidad Retroactiva
- `id_pregunta` puede no existir en ex√°menes antiguos
- Se maneja con `.get("id_pregunta", None)`

### 4. Validaci√≥n de Entrada
- Verifica que el examen sea tipo `"completado"`
- Lanza excepciones descriptivas para debugging

---

## üöÄ Pr√≥ximos Pasos (Fuera del Alcance del M√≥dulo 1)

1. **M√≥dulo 2:** Agrupador de Errores por Tema
2. **M√≥dulo 3:** Generador de Pr√°cticas Focalizadas
3. **Integraci√≥n con API:** Endpoints REST en `api_server.py`
4. **Dashboard Visual:** Gr√°ficas de patrones de error
5. **Hist√≥rico de Progreso:** An√°lisis longitudinal

---

## üìö Referencias

- **Sistema Examinator:** `DOCUMENTACION_COMPLETA_SISTEMA.md`
- **Estructura JSON de Ex√°menes:** `examenes/**/*.json`
- **Generador de Ex√°menes:** `generador_unificado.py`
- **API Principal:** `api_server.py`

---

## ‚úÖ Checklist de Implementaci√≥n

- [x] Dise√±ar estructura de clases
- [x] Implementar `ResultadoPreguntaExtendido`
- [x] Implementar `DetectorErrores.analizar_examen()`
- [x] Implementar clasificaci√≥n por tipo de pregunta
- [x] Implementar filtrado por estado
- [x] Implementar generaci√≥n de reportes
- [x] Documentar API completa
- [ ] Tests unitarios (siguiente tarea)
- [ ] Integraci√≥n con sistema existente
- [ ] Documentaci√≥n de usuario

---

**Versi√≥n:** 1.0  
**Fecha:** 22 de noviembre de 2025  
**Autor:** GitHub Copilot  
**Estado:** ‚úÖ Dise√±o Completo - Listo para Testing
