# ‚úÖ Sistema Actualizado - Ahora usa GPU con Ollama

## üéØ Cambios Realizados

### 1. **examinator_interactivo.py**
Ahora usa Ollama autom√°ticamente con GPU:
```bash
python examinator_interactivo.py documento.txt
```

### 2. **api_server.py** 
El servidor web ahora inicia con Ollama + GPU:
```bash
python api_server.py
```

### 3. **test_gpu.py** (NUEVO)
Script de prueba r√°pida:
```bash
python test_gpu.py
```

## üöÄ C√≥mo Usar

### Opci√≥n 1: Script de prueba
```powershell
python test_gpu.py
```

### Opci√≥n 2: Modo interactivo
```powershell
# Crear archivo de texto con contenido
echo "Python es un lenguaje..." > contenido.txt

# Generar examen
python examinator_interactivo.py contenido.txt
```

### Opci√≥n 3: Servidor web
```powershell
python api_server.py
```
Luego abre: http://localhost:8000

## üéÆ Cambiar Modelo

Edita estos archivos para usar otro modelo:

**En examinator_interactivo.py (l√≠nea ~193):**
```python
generador = GeneradorUnificado(
    usar_ollama=True,
    modelo_ollama="llama31-local",  # Cambia aqu√≠
    modelo_path_gguf=args.modelo,
    n_gpu_layers=35
)
```

**Modelos disponibles:**
- `llama31-local` (4.9 GB) - ‚≠ê Mejor balance
- `llama32-local` (2.0 GB) - M√°s r√°pido
- `qwen-local` (2.1 GB) - Bueno en espa√±ol
- `deepseek-r1-local` (6.7 GB) - Razonamiento avanzado

## üìä Verificar GPU

Durante la ejecuci√≥n, abre otra terminal:
```powershell
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" ps
```

Deber√≠as ver algo como:
```
NAME              PROCESSOR        SIZE
llama31-local     78% GPU/22% CPU  6.4 GB
```

## üîß Si Ollama no est√° disponible

El sistema autom√°ticamente regresar√° a usar modelos GGUF con llama-cpp-python:
```
‚ö†Ô∏è  Ollama no disponible
üí° Intentando con modelo GGUF...
```

## üí° Ventajas de la Nueva Configuraci√≥n

‚úÖ **GPU autom√°tica** - No necesitas configurar `n_gpu_layers`
‚úÖ **M√°s r√°pido** - Ollama est√° optimizado
‚úÖ **Fallback autom√°tico** - Si Ollama falla, usa GGUF
‚úÖ **F√°cil cambio de modelo** - Solo cambiar nombre
‚úÖ **Sin recompilar** - No necesitas CUDA toolkit

## üìù Ejemplo Completo

```powershell
# 1. Crear contenido
@"
Python es un lenguaje de programaci√≥n de alto nivel.
Fue creado por Guido van Rossum en 1991.
"@ | Out-File -FilePath test_contenido.txt -Encoding UTF8

# 2. Generar examen con GPU
python test_gpu.py

# 3. Verificar GPU
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" ps
```

## üéâ ¬°Todo listo!

Tu sistema ahora:
- ‚úÖ Usa GPU autom√°ticamente con Ollama
- ‚úÖ Genera ex√°menes 5-10x m√°s r√°pido
- ‚úÖ Tiene 5 modelos disponibles
- ‚úÖ Fallback a CPU si es necesario
