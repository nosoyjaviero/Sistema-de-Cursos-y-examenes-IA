# Comandos R√°pidos - Ollama con GPU

## üöÄ Verificar Estado

```powershell
# Ver modelos instalados
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" list

# Ver modelos en ejecuci√≥n (y uso de GPU)
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" ps

# Versi√≥n de Ollama
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" --version
```

## üì• Gesti√≥n de Modelos

```powershell
# Descargar modelo
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" pull llama3.2:3b

# Eliminar modelo
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" rm llama3.2:3b

# Ver informaci√≥n de modelo
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" show llama3.2:3b
```

## üß™ Probar Modelos

```powershell
# Chat interactivo
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" run llama3.2:3b

# Prueba r√°pida
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" run llama3.2:3b "Explica qu√© es Python en 50 palabras"
```

## üîß Scripts del Proyecto

```powershell
# Test simple con Ollama
python generador_examenes_ollama.py

# Generador unificado (detecta Ollama o llama-cpp-python)
python generador_unificado.py

# Comparar rendimiento GPU vs CPU
python comparar_rendimiento.py

# Script de inicio interactivo
.\iniciar_ollama.ps1
```

## üéÆ Verificar GPU

```powershell
# Verificar GPU NVIDIA
nvidia-smi

# Ver uso de Ollama
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" ps
# Si dice "100% GPU" = ¬°Funcionando correctamente!
```

## üêõ Soluci√≥n de Problemas

```powershell
# Si Ollama no responde
Get-Process ollama | Stop-Process -Force
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" serve

# Ver logs de Ollama
Get-Content "$env:LOCALAPPDATA\Ollama\logs\server.log" -Tail 50

# Reiniciar servicio completo
Get-Service Ollama* | Restart-Service
```

## üì¶ Modelos Recomendados

```powershell
# Peque√±o y r√°pido (1.3 GB) - Mejor para pruebas
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" pull llama3.2:1b

# Balance calidad/velocidad (2.0 GB) - ACTUAL ‚úÖ
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" pull llama3.2:3b

# Mayor precisi√≥n (4.7 GB) - Para producci√≥n
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" pull llama3.1:8b

# Especializado en c√≥digo (4.7 GB)
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" pull deepseek-coder:6.7b

# Bueno en espa√±ol (2.0 GB)
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" pull qwen2.5:3b
```

## üîó API REST de Ollama

```powershell
# Listar modelos (desde Python/PowerShell)
Invoke-RestMethod -Uri "http://localhost:11434/api/tags" | ConvertTo-Json

# Generar texto
$body = @{
    model = "llama3.2:3b"
    prompt = "¬øQu√© es Python?"
    stream = $false
} | ConvertTo-Json

Invoke-RestMethod -Uri "http://localhost:11434/api/generate" -Method Post -Body $body -ContentType "application/json"
```

## üíæ Ubicaciones de Archivos

```powershell
# Modelos de Ollama
explorer "$env:LOCALAPPDATA\Ollama\models"

# Logs
explorer "$env:LOCALAPPDATA\Ollama\logs"

# Ejecutable
explorer "$env:LOCALAPPDATA\Programs\Ollama"
```

## üéØ Alias √ötiles (A√±adir a $PROFILE)

```powershell
# Abrir perfil de PowerShell
notepad $PROFILE

# A√±adir estos alias:
function ollama { & "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" $args }
function ollama-ps { ollama ps }
function ollama-list { ollama list }
function ollama-gpu { ollama ps | Select-String "GPU" }

# Recargar perfil
. $PROFILE
```

Despu√©s de a√±adir los alias, podr√°s usar simplemente:
```powershell
ollama list
ollama-ps
ollama-gpu
```

## üìä Ejemplo de Uso en Proyecto

```python
# En tu c√≥digo Python
import requests

def generar_con_ollama(prompt):
    response = requests.post(
        "http://localhost:11434/api/generate",
        json={
            "model": "llama3.2:3b",
            "prompt": prompt,
            "stream": False
        }
    )
    return response.json()['response']

# Usar
resultado = generar_con_ollama("Genera 3 preguntas sobre Python")
print(resultado)
```

## ‚ú® Estado Actual

- ‚úÖ Ollama instalado: v0.12.11
- ‚úÖ Modelo activo: llama3.2:3b (2.0 GB)
- ‚úÖ GPU: Detectada y activa al 100%
- ‚úÖ Scripts listos para usar

¬°Todo configurado! üöÄ
