"""
Adaptador para usar Ollama o llama-cpp-python de forma transparente
"""
from pathlib import Path
from typing import List, Dict, Optional
import json
import requests
from datetime import datetime
from generador_examenes import PreguntaExamen


class GeneradorUnificado:
    """Generador que puede usar Ollama o llama-cpp-python"""
    
    def __init__(self, usar_ollama: bool = True, modelo_ollama: str = "llama3.2:3b", 
                 modelo_path_gguf: str = None, n_gpu_layers: int = 35):
        self.usar_ollama = usar_ollama
        self.modelo_ollama = modelo_ollama
        # Convertir path relativo a absoluto
        if modelo_path_gguf:
            modelo_path = Path(modelo_path_gguf)
            if not modelo_path.is_absolute():
                modelo_path = Path.cwd() / modelo_path
            self.modelo_path_gguf = str(modelo_path)
        else:
            self.modelo_path_gguf = None
        self.n_gpu_layers = n_gpu_layers
        self.llm = None
        
        # Sistema de logging detallado
        self.log_dir = Path("logs_practicas_detallado")
        self.log_dir.mkdir(exist_ok=True)
        self.current_log_file = None
        self.log_data = {}
        
        if usar_ollama:
            self._verificar_ollama()
        else:
            self._cargar_modelo_gguf()
    
    def _verificar_ollama(self):
        """Verifica que Ollama est√© disponible"""
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=2)
            if response.status_code == 200:
                modelos = response.json().get('models', [])
                print(f"‚úÖ Ollama activo - {len(modelos)} modelos")
                if not any(m['name'].startswith(self.modelo_ollama.split(':')[0]) for m in modelos):
                    print(f"‚ö†Ô∏è Modelo {self.modelo_ollama} no encontrado")
                    print(f"   Ejecuta: ollama pull {self.modelo_ollama}")
            else:
                print("‚ö†Ô∏è Ollama no responde")
                self.usar_ollama = False
        except Exception as e:
            print(f"‚ùå Ollama no disponible: {e}")
            print("üí° Usando llama-cpp-python como fallback")
            self.usar_ollama = False
            if self.modelo_path_gguf:
                self._cargar_modelo_gguf()
    
    def _cargar_modelo_gguf(self):
        """Carga modelo GGUF con llama-cpp-python"""
        if not self.modelo_path_gguf:
            print("‚ö†Ô∏è No hay modelo GGUF configurado")
            return
        
        try:
            from llama_cpp import Llama
            print(f"üîÑ Cargando GGUF: {self.modelo_path_gguf}")
            self.llm = Llama(
                model_path=self.modelo_path_gguf,
                n_ctx=8192,
                n_threads=6,
                n_gpu_layers=self.n_gpu_layers,
                verbose=False
            )
            gpu_info = f"GPU activada ({self.n_gpu_layers} capas)" if self.n_gpu_layers > 0 else "Solo CPU"
            print(f"‚úÖ Modelo GGUF cargado - {gpu_info}")
        except Exception as e:
            print(f"‚ùå Error cargando GGUF: {e}")
            self.llm = None
    
    def _iniciar_log(self):
        """Inicia un nuevo archivo de log para esta consulta en carpeta √∫nica"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Crear carpeta √∫nica para esta consulta
        carpeta_consulta = self.log_dir / f"practica_{timestamp}"
        carpeta_consulta.mkdir(parents=True, exist_ok=True)
        
        # Archivo de log dentro de la carpeta
        self.current_log_file = carpeta_consulta / f"practica_{timestamp}.log"
        
        self.log_data = {
            "timestamp": timestamp,
            "fecha_hora": datetime.now().isoformat(),
            "request": {},
            "prompt_enviado": "",
            "respuesta_modelo": "",
            "json_extraido": "",
            "preguntas_parseadas": [],
            "filtrado": {},
            "resultado_final": [],
            "errores": []
        }
        print(f"\nüìã Log detallado: {self.current_log_file}")
    
    def _agregar_log(self, seccion: str, datos: dict):
        """Agrega informaci√≥n a una secci√≥n del log"""
        if seccion in self.log_data:
            if isinstance(self.log_data[seccion], dict):
                self.log_data[seccion].update(datos)
            elif isinstance(self.log_data[seccion], list):
                self.log_data[seccion].append(datos)
            else:
                self.log_data[seccion] = datos
        else:
            self.log_data[seccion] = datos
    
    def _guardar_log(self):
        """Guarda el log completo en archivo"""
        if not self.current_log_file:
            return
        
        try:
            # Determinar si fue exitoso o fall√≥
            errores = self.log_data.get('errores', [])
            resultado_final = self.log_data.get('resultado_final', [])
            num_preguntas_solicitadas = sum(self.log_data.get('request', {}).get('num_preguntas', {}).values())
            num_preguntas_generadas = len(resultado_final)
            
            exitoso = len(errores) == 0 and num_preguntas_generadas > 0
            estado = "‚úÖ EXITOSO" if exitoso else "‚ùå FALL√ì"
            
            # Crear versi√≥n legible
            with open(self.current_log_file, 'w', encoding='utf-8') as f:
                f.write("="*80 + "\n")
                f.write("LOG DETALLADO DE GENERACI√ìN DE PR√ÅCTICA\n")
                f.write("="*80 + "\n\n")
                
                # RESUMEN EJECUTIVO
                f.write("üéØ RESUMEN EJECUTIVO\n")
                f.write("-"*80 + "\n")
                f.write(f"Estado: {estado}\n")
                f.write(f"Fecha/Hora: {self.log_data['fecha_hora']}\n")
                f.write(f"Preguntas solicitadas: {num_preguntas_solicitadas}\n")
                f.write(f"Preguntas generadas: {num_preguntas_generadas}\n")
                
                if errores:
                    f.write(f"\n‚ö†Ô∏è ERRORES ENCONTRADOS ({len(errores)}):\n")
                    for i, error in enumerate(errores, 1):
                        f.write(f"  {i}. {error}\n")
                else:
                    f.write(f"\n‚úÖ Sin errores\n")
                
                # Detalles del filtrado si existe
                filtrado = self.log_data.get('filtrado', {})
                if filtrado:
                    f.write(f"\nFiltrado:\n")
                    f.write(f"  ‚Ä¢ Total generadas: {filtrado.get('total_generadas', 0)}\n")
                    f.write(f"  ‚Ä¢ Total filtradas: {filtrado.get('total_filtradas', 0)}\n")
                    contador = filtrado.get('contador_por_tipo', {})
                    if contador:
                        f.write(f"  ‚Ä¢ Por tipo: {contador}\n")
                
                f.write("\n" + "="*80 + "\n\n")
                
                # REQUEST RECIBIDO
                f.write("-"*80 + "\n")
                f.write("1. REQUEST RECIBIDO DEL FRONTEND\n")
                f.write("-"*80 + "\n")
                for key, value in self.log_data.get('request', {}).items():
                    f.write(f"{key}: {value}\n")
                f.write("\n")
                
                # PROMPT ENVIADO AL MODELO
                f.write("-"*80 + "\n")
                f.write("2. PROMPT ENVIADO AL MODELO\n")
                f.write("-"*80 + "\n")
                f.write(f"Longitud: {len(self.log_data.get('prompt_enviado', ''))} caracteres\n\n")
                f.write(self.log_data.get('prompt_enviado', 'No disponible'))
                f.write("\n\n")
                
                # RESPUESTA DEL MODELO
                f.write("-"*80 + "\n")
                f.write("3. RESPUESTA COMPLETA DEL MODELO\n")
                f.write("-"*80 + "\n")
                f.write(f"Longitud: {len(self.log_data.get('respuesta_modelo', ''))} caracteres\n\n")
                f.write(self.log_data.get('respuesta_modelo', 'No disponible'))
                f.write("\n\n")
                
                # JSON EXTRA√çDO
                f.write("-"*80 + "\n")
                f.write("4. JSON EXTRA√çDO Y PARSEADO\n")
                f.write("-"*80 + "\n")
                json_str = self.log_data.get('json_extraido', '')
                if json_str:
                    try:
                        json_obj = json.loads(json_str) if isinstance(json_str, str) else json_str
                        f.write(json.dumps(json_obj, indent=2, ensure_ascii=False))
                    except:
                        f.write(str(json_str))
                else:
                    f.write("No se extrajo JSON")
                f.write("\n\n")
                
                # PREGUNTAS PARSEADAS
                f.write("-"*80 + "\n")
                f.write("5. PREGUNTAS PARSEADAS (Objetos Python)\n")
                f.write("-"*80 + "\n")
                for i, pregunta in enumerate(self.log_data.get('preguntas_parseadas', []), 1):
                    f.write(f"\nPregunta {i}:\n")
                    f.write(json.dumps(pregunta, indent=2, ensure_ascii=False))
                    f.write("\n")
                f.write("\n")
                
                # FILTRADO
                f.write("-"*80 + "\n")
                f.write("6. PROCESO DE FILTRADO\n")
                f.write("-"*80 + "\n")
                filtrado = self.log_data.get('filtrado', {})
                for key, value in filtrado.items():
                    f.write(f"{key}: {value}\n")
                f.write("\n")
                
                # RESULTADO FINAL
                f.write("-"*80 + "\n")
                f.write("7. RESULTADO FINAL DEVUELTO AL FRONTEND\n")
                f.write("-"*80 + "\n")
                f.write(f"Total preguntas: {len(self.log_data.get('resultado_final', []))}\n\n")
                for i, pregunta in enumerate(self.log_data.get('resultado_final', []), 1):
                    f.write(f"\nPregunta {i}:\n")
                    f.write(json.dumps(pregunta, indent=2, ensure_ascii=False))
                    f.write("\n")
                f.write("\n")
                
                # ERRORES
                if self.log_data.get('errores'):
                    f.write("-"*80 + "\n")
                    f.write("8. ERRORES ENCONTRADOS\n")
                    f.write("-"*80 + "\n")
                    for error in self.log_data['errores']:
                        f.write(f"‚Ä¢ {error}\n")
                    f.write("\n")
                
                f.write("="*80 + "\n")
                f.write("FIN DEL LOG\n")
                f.write("="*80 + "\n")
            
            # Guardar tambi√©n versi√≥n JSON
            json_file = self.current_log_file.with_suffix('.json')
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(self.log_data, f, indent=2, ensure_ascii=False)
            
            print(f"‚úÖ Log guardado: {self.current_log_file}")
            print(f"‚úÖ JSON guardado: {json_file}")
            
        except Exception as e:
            print(f"‚ùå Error guardando log: {e}")
    
    def _generar_ollama(self, prompt: str, max_tokens: int, temperature: float) -> str:
        """Genera con Ollama"""
        try:
            # Detectar modelos lentos y ajustar solo el timeout
            es_deepseek = 'deepseek' in self.modelo_ollama.lower()
            
            # Determinar si se usa GPU basado en n_gpu_layers
            usar_gpu = self.n_gpu_layers > 0
            modo_gpu = "GPU activada" if usar_gpu else "Solo CPU"
            
            print(f"\n{'='*60}")
            print(f"üéÆ Modelo Ollama: {self.modelo_ollama}")
            print(f"‚öôÔ∏è  Configuraci√≥n:")
            print(f"   ‚Ä¢ Modo: {modo_gpu}")
            print(f"   ‚Ä¢ Temperature: {temperature}")
            print(f"   ‚Ä¢ Max tokens: {max_tokens}")
            print(f"   ‚Ä¢ Prompt length: {len(prompt)} caracteres")
            
            if es_deepseek:
                print(f"   ‚Ä¢ Modelo de razonamiento: DeepSeek-R1")
                print(f"   ‚Ä¢ Genera razonamiento interno antes de responder")
            print(f"{'='*60}\n")
            
            # Debug: mostrar inicio del prompt
            print(f"üìù INICIO DEL PROMPT (primeros 500 chars):")
            print(f"{prompt[:500]}")
            print(f"...\n")
            
            # Timeout ajustado seg√∫n modelo (sin cambiar max_tokens)
            if es_deepseek:
                timeout_segundos = 1800  # 30 minutos para DeepSeek-R1
                print(f"‚è±Ô∏è  Timeout configurado: {timeout_segundos} segundos (30 minutos)")
                print(f"üí° DeepSeek-R1 hace razonamiento complejo y puede tardar mucho")
                print(f"üí° Vale la pena esperar por la calidad de sus respuestas...")
            else:
                timeout_segundos = 600  # 10 minutos para otros modelos
                print(f"‚è±Ô∏è  Timeout configurado: {timeout_segundos} segundos (10 minutos)")
                print(f"üí° Modelos grandes pueden tardar varios minutos...")
            print(f"üí° Modelos grandes pueden tardar varios minutos...")
            print(f"üöÄ Enviando request a Ollama...\n")
            
            # Ajustar prompt para DeepSeek-R1 (permitir razonamiento, pero pedir JSON al final)
            prompt_final = prompt
            if es_deepseek:
                # DeepSeek-R1 es un modelo de razonamiento - dejarlo razonar pero pedir JSON al final
                prompt_final = f"""{prompt}

IMPORTANTE: Despu√©s de tu an√°lisis, DEBES generar el JSON v√°lido con la estructura solicitada.
El JSON debe comenzar con {{ y terminar con }}.
Puedes razonar primero, pero al final SIEMPRE incluye el JSON completo."""
                print(f"üìù Prompt adaptado para DeepSeek-R1 (permite razonamiento + JSON al final)\n")
            
            # Configurar opciones seg√∫n modo GPU/CPU
            opciones = {
                "temperature": temperature,
                "num_predict": max_tokens,
                "stop": ["<|eot_id|>", "<|end_of_text|>", "\n\n\n"]
            }
            
            # Si n_gpu_layers es 0, forzar uso de CPU
            if not usar_gpu:
                opciones["num_gpu"] = 0
                print(f"üî∑ Modo CPU forzado (num_gpu=0)\n")
            
            response = requests.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": self.modelo_ollama,
                    "prompt": prompt_final,
                    "stream": False,
                    "options": opciones
                },
                timeout=timeout_segundos
            )
            
            print(f"üì¨ Response status: {response.status_code}")
            
            if response.status_code == 200:
                print(f"‚úÖ Generaci√≥n completada ({modo_gpu})\n")
                respuesta_json = response.json()
                respuesta_completa = respuesta_json.get('response', '')
                
                if not respuesta_completa:
                    print(f"‚ö†Ô∏è ADVERTENCIA: Respuesta vac√≠a")
                    print(f"   JSON completo: {respuesta_json}")
                    return None
                
                # Debug: Guardar respuesta completa
                print(f"üìù Longitud de respuesta: {len(respuesta_completa)} caracteres")
                print(f"üìÑ Primeros 500 caracteres:\n{respuesta_completa[:500]}\n")
                if len(respuesta_completa) > 500:
                    print(f"üìÑ √öltimos 500 caracteres:\n{respuesta_completa[-500:]}\n")
                
                return respuesta_completa
            else:
                error_detail = response.text if response.text else "Sin detalles"
                print(f"‚ùå Error Ollama {response.status_code}")
                print(f"   Detalles: {error_detail[:500]}")
                return None
        except requests.exceptions.Timeout:
            print(f"‚è±Ô∏è TIMEOUT: La generaci√≥n excedi√≥ {timeout_segundos} segundos")
            print(f"   Considera usar menos preguntas o un modelo m√°s peque√±o")
            return None
        except Exception as e:
            print(f"‚ùå Error Ollama: {type(e).__name__}: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _generar_ollama_chat(self, messages: list, max_tokens: int, temperature: float) -> str:
        """Genera con Ollama usando API de chat (mantiene historial/contexto)"""
        try:
            # Determinar si se usa GPU basado en n_gpu_layers
            usar_gpu = self.n_gpu_layers > 0
            modo_gpu = "GPU activada" if usar_gpu else "Solo CPU"
            
            print(f"\n{'='*60}")
            print(f"üí¨ CHAT CON CONTEXTO - Modelo Ollama: {self.modelo_ollama}")
            print(f"‚öôÔ∏è  Configuraci√≥n:")
            print(f"   ‚Ä¢ Modo: {modo_gpu}")
            print(f"   ‚Ä¢ Temperature: {temperature}")
            print(f"   ‚Ä¢ Max tokens: {max_tokens}")
            print(f"   ‚Ä¢ Mensajes en historial: {len(messages)}")
            print(f"{'='*60}\n")
            
            # Debug: mostrar estructura de mensajes
            print(f"üìú Estructura del chat:")
            for i, msg in enumerate(messages):
                role = msg.get('role', 'unknown')
                content_preview = msg.get('content', '')[:100]
                print(f"   {i+1}. {role}: {content_preview}...")
            print()
            
            # Timeout m√°s largo para modelos grandes
            timeout_segundos = 120  # 2 minutos (reducido para evitar cuelgues largos)
            print(f"‚è±Ô∏è  Timeout configurado: {timeout_segundos} segundos")
            print(f"üöÄ Enviando request a Ollama API de chat...\n")
            
            # Configurar opciones seg√∫n modo GPU/CPU
            opciones = {
                "temperature": temperature,
                "num_predict": max_tokens,
                "num_ctx": 8192,  # Contexto amplio para mantener conversaciones largas
                "stop": ["<|eot_id|>", "<|end_of_text|>"]
            }
            
            # Si n_gpu_layers es 0, forzar uso de CPU
            if not usar_gpu:
                opciones["num_gpu"] = 0
                print(f"üî∑ Modo CPU forzado (num_gpu=0)\n")
            
            # Intentar primero con historial completo
            for intento in range(2):
                try:
                    # En el segundo intento, reducir historial si falla
                    messages_a_enviar = messages
                    if intento == 1:
                        print(f"üîÑ Reintentando con historial reducido...")
                        # Mantener solo system + √∫ltimos 6 mensajes (3 intercambios)
                        messages_a_enviar = [messages[0]] + messages[-6:]
                        opciones["num_ctx"] = 4096  # Mantener contexto razonable en reintento
                    
                    response = requests.post(
                        "http://localhost:11434/api/chat",
                        json={
                            "model": self.modelo_ollama,
                            "messages": messages_a_enviar,
                            "stream": False,
                            "options": opciones
                        },
                        timeout=timeout_segundos
                    )
                    
                    print(f"üì¨ Response status: {response.status_code}")
                    
                    if response.status_code == 200:
                        print(f"‚úÖ Generaci√≥n completada ({modo_gpu} y contexto)\n")
                        respuesta_json = response.json()
                        
                        # La API de chat devuelve el mensaje en un formato diferente
                        mensaje_respuesta = respuesta_json.get('message', {})
                        respuesta_completa = mensaje_respuesta.get('content', '')
                        
                        if not respuesta_completa:
                            print(f"‚ö†Ô∏è ADVERTENCIA: Respuesta vac√≠a")
                            print(f"   JSON completo: {respuesta_json}")
                            if intento == 0:
                                continue  # Reintentar
                            return None
                        
                        # Debug: Guardar respuesta completa
                        print(f"üìù Longitud de respuesta: {len(respuesta_completa)} caracteres")
                        print(f"üìÑ Primeros 300 caracteres:\n{respuesta_completa[:300]}\n")
                        
                        return respuesta_completa
                    else:
                        error_detail = response.text if response.text else "Sin detalles"
                        print(f"‚ùå Error Ollama {response.status_code}")
                        print(f"   Detalles: {error_detail[:500]}")
                        
                        # Si es error 500 y es el primer intento, reintentar
                        if response.status_code == 500 and intento == 0:
                            print(f"üîÑ Ollama crashe√≥, reintentando con configuraci√≥n reducida...")
                            continue
                        return None
                        
                except requests.exceptions.RequestException as e:
                    if intento == 0:
                        print(f"‚ö†Ô∏è Error en intento {intento + 1}: {e}")
                        continue
                    raise
            
            return None
            
        except requests.exceptions.Timeout:
            print(f"‚è±Ô∏è TIMEOUT: La generaci√≥n excedi√≥ {timeout_segundos} segundos")
            print(f"   Considera reducir el historial o usar un modelo m√°s peque√±o")
            return None
        except Exception as e:
            print(f"‚ùå Error Ollama Chat: {type(e).__name__}: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _generar_gguf(self, prompt: str, max_tokens: int, temperature: float, 
                     top_p: float, repeat_penalty: float) -> str:
        """Genera con llama-cpp-python"""
        if not self.llm:
            return None
        
        try:
            resp = self.llm(
                prompt,
                max_tokens=max_tokens,
                temperature=temperature,
                top_p=top_p,
                repeat_penalty=repeat_penalty,
                stop=["<|eot_id|>", "<|end_of_text|>", "```"]
            )
            return resp['choices'][0]['text']
        except Exception as e:
            print(f"‚ùå Error GGUF: {e}")
            return None
    
    def generar_examen(self, contenido_documento: str, 
                      num_preguntas: Dict[str, int] = None,
                      callback_progreso = None,
                      ajustes_modelo: dict = None,
                      archivos: list = None,
                      session_id: str = None,
                      sin_prompt_sistema: bool = False,
                      tipo_caso: str = None) -> List[PreguntaExamen]:
        """Genera examen usando Ollama o GGUF
        sin_prompt_sistema: Si es True, usa el contenido directamente sin agregar instrucciones
        tipo_caso: Para casos de estudio, especifica el tipo (descriptivo, analitico, resolucion, etc.)
        """
        
        # INICIAR LOG DETALLADO
        self._iniciar_log()
        
        if num_preguntas is None:
            num_preguntas = {'multiple': 6, 'verdadero_falso': 4, 'corta': 2}
        
        if ajustes_modelo is None:
            ajustes_modelo = {
                'temperature': 0.7,  # Aumentado para m√°xima variedad y evitar duplicados
                'max_tokens': 3000,
                'top_p': 0.9,
                'repeat_penalty': 1.15
            }
        
        # Registrar request
        self._agregar_log('request', {
            'num_preguntas': num_preguntas,
            'ajustes_modelo': ajustes_modelo,
            'sin_prompt_sistema': sin_prompt_sistema,
            'tipo_caso': tipo_caso,
            'usar_ollama': self.usar_ollama,
            'modelo': self.modelo_ollama if self.usar_ollama else self.modelo_path_gguf,
            'contenido_length': len(contenido_documento)
        })
        
        if callback_progreso:
            callback_progreso(15, "Preparando prompt...")
        
        # Verificar que contenido_documento es un string
        if not isinstance(contenido_documento, str):
            error_msg = f"contenido_documento no es string, es {type(contenido_documento)}"
            print(f"‚ùå ERROR: {error_msg}")
            self._agregar_log('errores', error_msg)
            self._guardar_log()
            raise TypeError(f"contenido_documento debe ser string, recibido: {type(contenido_documento)}")
        
        # Crear prompt
        contenido_corto = contenido_documento[:8000]
        
        # Mantener tipos originales para el prompt (case_study necesita su formato especial)
        num_preguntas_prompt = num_preguntas.copy()
        tiene_casos = num_preguntas.get('case_study', 0) > 0 or num_preguntas.get('caso_estudio', 0) > 0
        
        total = sum(num_preguntas.values())
        
        if tiene_casos:
            # CASOS DE ESTUDIO: Usar SIEMPRE el formato estructurado detallado
            # Extraer solo el CONTENIDO real (despu√©s de "CONTENIDO:")
            if "CONTENIDO:" in contenido_documento:
                # El prompt del usuario tiene formato "prompt_personalizado\n\nCONTENIDO:\ncontenido_real"
                partes = contenido_documento.split("CONTENIDO:", 1)
                if len(partes) > 1:
                    contenido_corto = partes[1].strip()[:8000]
            
            prompt = self._crear_prompt(contenido_corto, num_preguntas_prompt, total, tipo_caso)
            print(f"üéØ CASOS DE ESTUDIO DETECTADOS: Usando prompt estructurado con tipo '{tipo_caso}'")
            print(f"   Contenido extra√≠do: {len(contenido_corto)} caracteres")
        elif sin_prompt_sistema:
            # Modo prompt personalizado: usar contenido directamente (solo si NO hay casos de estudio)
            prompt = contenido_corto
            print(f"üéØ MODO PROMPT PERSONALIZADO: Usando prompt del usuario directamente")
        else:
            # Modo normal: agregar formato del sistema
            prompt = self._crear_prompt(contenido_corto, num_preguntas_prompt, total, tipo_caso)
        
        # Registrar prompt
        self._agregar_log('prompt_enviado', prompt)
        
        if callback_progreso:
            motor = "Ollama + GPU" if self.usar_ollama else "llama-cpp-python"
            callback_progreso(25, f"Generando con {motor}...")
        
        # NUEVA ESTRATEGIA: GENERAR POR BLOQUES PARA ASEGURAR TIPOS CORRECTOS
        print(f"\n{'='*60}")
        print(f"üéØ GENERACI√ìN POR BLOQUES - Total: {total} preguntas")
        print(f"{'='*60}")
        
        todas_preguntas = []
        progreso_base = 25
        progreso_por_tipo = 45 / len([v for v in num_preguntas.values() if v > 0])  # 45% para generaci√≥n
        
        for tipo, cantidad in num_preguntas.items():
            if cantidad == 0:
                continue
            
            print(f"\nüì¶ Bloque {len(todas_preguntas) + 1}: Generando {cantidad} preguntas de tipo '{tipo}'")
            
            # Crear prompt espec√≠fico para este tipo
            prompt_bloque = self._crear_prompt_por_tipo(contenido_corto, tipo, cantidad, tipo_caso)
            
            # Generar este bloque
            if self.usar_ollama:
                respuesta = self._generar_ollama(
                    prompt_bloque, 
                    ajustes_modelo['max_tokens'], 
                    ajustes_modelo['temperature']
                )
            else:
                respuesta = self._generar_gguf(
                    prompt_bloque,
                    ajustes_modelo['max_tokens'],
                    ajustes_modelo['temperature'],
                    ajustes_modelo['top_p'],
                    ajustes_modelo['repeat_penalty']
                )
            
            if not respuesta:
                print(f"‚ö†Ô∏è No se obtuvo respuesta para tipo '{tipo}'")
                continue
            
            # Parsear solo preguntas de este tipo
            preguntas_bloque = self._extraer_preguntas_simple(respuesta, tipo)
            
            # Tomar exactamente la cantidad solicitada
            preguntas_tipo_correcto = [p for p in preguntas_bloque if p.tipo == tipo][:cantidad]
            
            print(f"‚úÖ Bloque completado: {len(preguntas_tipo_correcto)}/{cantidad} preguntas de tipo '{tipo}'")
            todas_preguntas.extend(preguntas_tipo_correcto)
            
            # Actualizar progreso
            if callback_progreso:
                progreso_base += progreso_por_tipo
                callback_progreso(int(progreso_base), f"Generadas {len(todas_preguntas)}/{total}...")
        
        # Registrar todas las respuestas
        self._agregar_log('total_preguntas_generadas', len(todas_preguntas))
        
        if callback_progreso:
            callback_progreso(70, "Procesando respuesta...")
        
        print(f"\n{'='*60}")
        print(f"‚úÖ GENERACI√ìN COMPLETADA: {len(todas_preguntas)}/{total} preguntas")
        print(f"{'='*60}")
        
        if callback_progreso:
            callback_progreso(100, f"¬°{len(todas_preguntas)} preguntas generadas!")
        
        return todas_preguntas
    
    def _crear_prompt_caso_estudio(self, contenido: str, cantidad: int, tipo_caso: str) -> str:
        """Crea un prompt especializado para casos de estudio seg√∫n el subtipo seleccionado"""
        
        # Mapeo de tipos de casos de estudio con instrucciones espec√≠ficas
        tipos_casos = {
            'descriptivo': {
                'nombre': 'Caso Descriptivo',
                'descripcion': 'Describe qu√© pas√≥, qui√©n hizo qu√© y el contexto completo',
                'objetivo': 'Aprender a observar, sintetizar y entender el contexto',
                'instrucciones': '''- Formula un caso que DESCRIBA una situaci√≥n real extra√≠da del contenido
- Incluye: actores involucrados, contexto temporal, acciones realizadas, resultados obtenidos
- Enf√≥cate en QU√â pas√≥, no en por qu√© o c√≥mo solucionarlo
- El caso debe permitir al estudiante practicar observaci√≥n y s√≠ntesis'''
            },
            'analitico': {
                'nombre': 'Caso Anal√≠tico-Diagn√≥stico',
                'descripcion': 'Explica causas, relaciones y consecuencias (autopsia empresarial)',
                'objetivo': 'Analizar causas ra√≠z y relaciones causa-efecto',
                'instrucciones': '''- Formula un caso que requiera ANALIZAR causas, relaciones y consecuencias
- Incluye: s√≠ntomas observables, datos relevantes, m√∫ltiples factores interrelacionados
- El estudiante debe identificar causas ra√≠z y explicar cadenas de causalidad
- Requiere pensamiento sist√©mico y diagn√≥stico profundo'''
            },
            'resolucion': {
                'nombre': 'Caso de Resoluci√≥n de Problemas',
                'descripcion': 'Plantea un problema abierto que requiere soluci√≥n',
                'objetivo': 'Desarrollar habilidades de problem-solving',
                'instrucciones': '''- Formula un caso con un PROBLEMA CLARO que necesita soluci√≥n
- Incluye: descripci√≥n del problema, restricciones, recursos disponibles
- El problema debe ser abierto (m√∫ltiples soluciones posibles)
- El estudiante debe proponer Y justificar una soluci√≥n concreta'''
            },
            'decision': {
                'nombre': 'Caso de Decisi√≥n',
                'descripcion': 'Escenario donde se debe elegir entre varias opciones',
                'objetivo': 'Practicar toma de decisiones justificadas',
                'instrucciones': '''- Formula un caso donde se deba TOMAR UNA DECISI√ìN entre 2-4 opciones
- Incluye: contexto de decisi√≥n, opciones disponibles (con pros/contras), stakeholders afectados
- Ninguna opci√≥n es claramente superior - todas tienen trade-offs
- El estudiante debe elegir Y justificar exhaustivamente su decisi√≥n'''
            },
            'comparativo': {
                'nombre': 'Caso Comparativo',
                'descripcion': 'Compara dos soluciones, enfoques o metodolog√≠as',
                'objetivo': 'Entrenar evaluaci√≥n cr√≠tica comparativa',
                'instrucciones': '''- Formula un caso que compare 2-3 ALTERNATIVAS del contenido
- Incluye: criterios de comparaci√≥n, ventajas/desventajas de cada opci√≥n, contexto de aplicaci√≥n
- El estudiante debe evaluar cr√≠ticamente cada alternativa
- Debe recomendar cu√°l usar y en qu√© circunstancias'''
            },
            'predictivo': {
                'nombre': 'Caso Predictivo',
                'descripcion': 'Proyecta el futuro bas√°ndose en datos actuales',
                'objetivo': 'Desarrollar capacidad de pron√≥stico fundamentado',
                'instrucciones': '''- Formula un caso con DATOS ACTUALES donde se deba predecir el futuro
- Incluye: tendencias observadas, m√©tricas actuales, factores externos relevantes
- El estudiante debe hacer predicciones espec√≠ficas (no vagas)
- Debe justificar el pron√≥stico con evidencia y razonamiento l√≥gico'''
            },
            'simulacion': {
                'nombre': 'Caso de Simulaci√≥n',
                'descripcion': 'Sistema con variables din√°micas que requiere decisiones',
                'objetivo': 'Practicar decisiones en sistemas complejos',
                'instrucciones': '''- Formula un caso que simule un SISTEMA CON VARIABLES DIN√ÅMICAS
- Incluye: estado inicial, variables que interact√∫an, reglas del sistema
- El estudiante debe tomar decisiones secuenciales
- Debe predecir c√≥mo sus decisiones afectan las variables del sistema'''
            },
            'inverso': {
                'nombre': 'Caso Inverso (Reverse)',
                'descripcion': 'Se da el resultado final, se debe reconstruir el proceso',
                'objetivo': 'Desarrollar pensamiento deductivo e ingeniar√≠a inversa',
                'instrucciones': '''- Formula un caso mostrando el RESULTADO FINAL ya logrado
- Incluye: descripci√≥n detallada del outcome, pistas sobre el proceso
- OCULTA los pasos intermedios
- El estudiante debe reconstruir l√≥gicamente QU√â PASOS se siguieron para llegar a ese resultado'''
            },
            'fallo': {
                'nombre': 'Caso de Fallo o Desastre',
                'descripcion': 'Estudia algo que sali√≥ mal (aprender de errores ajenos)',
                'objetivo': 'Aprender de fracasos y prevenir errores',
                'instrucciones': '''- Formula un caso sobre algo que SALI√ì MAL bas√°ndote en el contenido
- Incluye: qu√© se intent√≥ lograr, qu√© fall√≥ espec√≠ficamente, consecuencias
- Menciona se√±ales de alerta que se ignoraron
- El estudiante debe analizar causas del fallo y proponer c√≥mo evitarlo'''
            },
            'creativo': {
                'nombre': 'Caso Creativo/Innovaci√≥n',
                'descripcion': 'No hay respuesta correcta, se eval√∫a creatividad',
                'objetivo': 'Fomentar ideaci√≥n y pensamiento original',
                'instrucciones': '''- Formula un caso ABIERTO que requiera INNOVACI√ìN
- Incluye: desaf√≠o o oportunidad, restricciones del contexto
- NO hay una respuesta "correcta" predefinida
- Se eval√∫a originalidad, viabilidad de ideas y creatividad de la propuesta'''
            },
            'etico': {
                'nombre': 'Caso √âtico',
                'descripcion': 'Dilema donde el negocio choca con la moral',
                'objetivo': 'Desarrollar razonamiento √©tico y responsabilidad',
                'instrucciones': '''- Formula un caso con un DILEMA √âTICO basado en el contenido
- Incluye: conflicto entre beneficio/deber, stakeholders con intereses contrapuestos
- No hay soluci√≥n f√°cil - hay tensi√≥n entre opciones
- El estudiante debe razonar √©ticamente y defender su postura moral'''
            },
            'tecnico': {
                'nombre': 'Caso T√©cnico-Operativo',
                'descripcion': 'Explica un sistema/proceso y reta a optimizarlo',
                'objetivo': 'Mejorar habilidades t√©cnicas y optimizaci√≥n',
                'instrucciones': '''- Formula un caso explicando un SISTEMA O PROCESO T√âCNICO del contenido
- Incluye: descripci√≥n del funcionamiento actual, m√©tricas de desempe√±o
- Identifica ineficiencias o √°reas de mejora
- El estudiante debe proponer optimizaciones t√©cnicas concretas y justificarlas'''
            }
        }
        
        # Si no se especifica tipo o es inv√°lido, usar descriptivo por defecto
        if not tipo_caso or tipo_caso not in tipos_casos:
            tipo_caso = 'descriptivo'
        
        info_tipo = tipos_casos[tipo_caso]
        
        prompt = f"""Eres un experto en crear casos de estudio educativos. Tu tarea es generar EXACTAMENTE {cantidad} caso(s) de estudio de tipo "{info_tipo['nombre']}" bas√°ndote en el contenido proporcionado.

CONTENIDO BASE PARA EL CASO:
{contenido}

üéØ TIPO DE CASO REQUERIDO: {info_tipo['nombre'].upper()}
üìã DESCRIPCI√ìN: {info_tipo['descripcion']}
üéì OBJETIVO PEDAG√ìGICO: {info_tipo['objetivo']}

‚ö†Ô∏è INSTRUCCIONES ESPEC√çFICAS PARA ESTE TIPO:
{info_tipo['instrucciones']}

‚ö†Ô∏è REGLAS CR√çTICAS:
1. DEBES formular el caso DE ESTUDIO COMPLETO bas√°ndote en la informaci√≥n del contenido
2. El caso debe ser REALISTA y coherente con el contenido proporcionado
3. Genera EXACTAMENTE {cantidad} caso(s) de tipo "{tipo_caso}"
4. NO generes otros tipos de casos
5. El caso debe estar COMPLETO con todos los campos requeridos
6. NO uses placeholders como "...", "[...]", "[Nombre de empresa]"
7. Usa informaci√≥n ESPEC√çFICA del contenido proporcionado
8. El caso debe ser autocontenido (incluye todo el contexto necesario)

FORMATO JSON REQUERIDO:
{{
  "preguntas": [
    {{
      "tipo": "case_study",
      "subtipo": "{tipo_caso}",
      "titulo": "T√≠tulo descriptivo del caso (m√°x 15 palabras)",
      "contexto": "CONTEXTO DETALLADO (m√≠nimo 100 palabras): Describe el escenario completo, actores involucrados, situaci√≥n inicial, antecedentes relevantes. Usa informaci√≥n ESPEC√çFICA del contenido.",
      "descripcion": "DESCRIPCI√ìN EXHAUSTIVA (m√≠nimo 150 palabras): Desarrolla el caso en profundidad seg√∫n el tipo '{tipo_caso}'. Incluye datos concretos, situaciones espec√≠ficas, detalles relevantes extra√≠dos del contenido.",
      "pregunta": "Pregunta principal que gu√≠a el an√°lisis del caso (relacionada con el tipo '{tipo_caso}')",
      "datos_clave": ["Dato relevante 1 del contenido", "Dato relevante 2 del contenido", "Dato relevante 3 del contenido", "Dato relevante 4 del contenido"],
      "respuesta_esperada": "Respuesta modelo DETALLADA (m√≠nimo 150 palabras) que muestre c√≥mo analizar/resolver este tipo de caso. Debe demostrar el tipo de razonamiento requerido para '{tipo_caso}'.",
      "puntos": 10
    }}
  ]
}}

IMPORTANTE: El caso debe formularse USANDO LA INFORMACI√ìN DEL CONTENIDO PROPORCIONADO, no inventes escenarios gen√©ricos. Extrae situaciones, conceptos, ejemplos o problemas del texto y desarr√≥llalos como un caso de estudio del tipo "{tipo_caso}".

Responde SOLO con JSON v√°lido, sin c√≥digo markdown ni explicaciones adicionales."""

        return prompt
    
    def _crear_prompt_por_tipo(self, contenido: str, tipo: str, cantidad: int, tipo_caso: str = None) -> str:
        """Crea un prompt espec√≠fico para generar preguntas de UN SOLO TIPO
        Esto asegura que el modelo genere exactamente el tipo solicitado
        """
        
        # CASOS DE ESTUDIO: Requieren prompt especial basado en el subtipo
        if tipo == 'case_study':
            return self._crear_prompt_caso_estudio(contenido, cantidad, tipo_caso)
        
        # Mapeo de nombres de tipos a descripciones
        tipo_info = {
            'mcq': {
                'nombre': 'opci√≥n m√∫ltiple',
                'puntos': 3,
                'ejemplo': '''{
      "tipo": "mcq",
      "pregunta": "¬øPregunta clara y espec√≠fica sobre el contenido?",
      "opciones": ["A) Primera opci√≥n", "B) Segunda opci√≥n", "C) Tercera opci√≥n", "D) Cuarta opci√≥n"],
      "respuesta_correcta": "A",
      "puntos": 3
    }''',
                'instrucciones': '- Debe tener EXACTAMENTE 4 opciones (A, B, C, D)\n- Una sola respuesta correcta\n- Las opciones incorrectas deben ser plausibles'
            },
            'true_false': {
                'nombre': 'verdadero/falso',
                'puntos': 2,
                'ejemplo': '''{
      "tipo": "true_false",
      "pregunta": "Afirmaci√≥n clara basada en el contenido",
      "respuesta_correcta": "verdadero",
      "puntos": 2
    }''',
                'instrucciones': '- La afirmaci√≥n debe ser clara y espec√≠fica\n- respuesta_correcta debe ser "verdadero" o "falso"\n- Basada en informaci√≥n del contenido'
            },
            'short_answer': {
                'nombre': 'respuesta corta',
                'puntos': 3,
                'ejemplo': '''{
      "tipo": "short_answer",
      "pregunta": "Pregunta que requiere una respuesta breve y concreta",
      "respuesta_correcta": "Respuesta esperada (2-3 oraciones)",
      "puntos": 3
    }''',
                'instrucciones': '- Respuesta de 2-3 oraciones\n- Clara y concreta\n- Basada en el contenido'
            },
            'cloze': {
                'nombre': 'relleno de huecos (cloze test)',
                'puntos': 3,
                'ejemplo': '''{
      "tipo": "cloze",
      "pregunta": "Python es un lenguaje de {} creado por {} en {}",
      "metadata": {
        "text_with_gaps": "Python es un lenguaje de {} creado por {} en {}",
        "answers": ["programaci√≥n", "Guido van Rossum", "1991"],
        "hint": "Piensa en el tipo de lenguaje y su creador"
      },
      "respuesta_correcta": "programaci√≥n, Guido van Rossum, 1991",
      "puntos": 3
    }''',
                'instrucciones': '- El texto debe tener 2-5 huecos marcados con {}\n- Cada hueco representa UNA palabra o frase corta clave\n- metadata.answers debe tener el MISMO n√∫mero de elementos que huecos\n- Las respuestas deben estar en el MISMO ORDEN que aparecen los huecos\n- Incluye una pista (hint) √∫til que ayude sin revelar la respuesta\n- El texto debe ser educativo y basado en el contenido'
            },
            'open_question': {
                'nombre': 'desarrollo/ensayo',
                'puntos': 5,
                'ejemplo': '''{
      "tipo": "open_question",
      "pregunta": "Analiza en profundidad el dise√±o centrado en el usuario. Explica sus principios fundamentales, beneficios principales y c√≥mo se aplica en proyectos reales. Desarrolla tu respuesta con ejemplos concretos.",
      "metadata": {
        "key_points": [
          "Definici√≥n de dise√±o centrado en usuario",
          "Principios fundamentales (enfoque en usuarios, medici√≥n emp√≠rica, dise√±o iterativo)",
          "Beneficios para usuarios y negocio",
          "Metodolog√≠as y t√©cnicas aplicadas",
          "Ejemplos concretos de implementaci√≥n"
        ],
        "expected_length": "150-300 palabras",
        "evaluation_criteria": [
          "Claridad conceptual y profundidad de an√°lisis",
          "Conexi√≥n entre teor√≠a y pr√°ctica",
          "Uso de ejemplos relevantes",
          "Estructura y coherencia argumentativa"
        ]
      },
      "respuesta_correcta": "El dise√±o centrado en el usuario (UCD) es una filosof√≠a de dise√±o que sit√∫a al usuario final en el centro del proceso de desarrollo. Sus principios fundamentales incluyen: 1) Enfoque temprano en usuarios y tareas, comprendiendo qui√©nes son, qu√© necesitan y en qu√© contexto operan. 2) Medici√≥n emp√≠rica mediante observaci√≥n del comportamiento real con prototipos. 3) Dise√±o iterativo con ciclos de dise√±o-prueba-refinamiento. Los beneficios son significativos: mayor satisfacci√≥n del usuario, reducci√≥n de costos al detectar problemas temprano, productos m√°s intuitivos y mejor adopci√≥n. Las metodolog√≠as comunes incluyen investigaci√≥n de usuarios, creaci√≥n de personas, pruebas de usabilidad y dise√±o participativo. Por ejemplo, al desarrollar una aplicaci√≥n bancaria, el UCD implica observar c√≥mo usuarios reales interact√∫an con prototipos, identificar fricciones en el flujo de pagos, y refinar iterativamente hasta lograr una experiencia fluida.",
      "puntos": 5
    }''',
                'instrucciones': '- Pregunta compleja que requiere an√°lisis profundo y estructurado\n- Debe solicitar expl√≠citamente: explicaci√≥n de conceptos, an√°lisis de relaciones, ejemplos concretos\n- metadata.key_points: Array con 4-6 aspectos espec√≠ficos que debe cubrir la respuesta\n- metadata.expected_length: Extensi√≥n esperada de la respuesta\n- metadata.evaluation_criteria: Criterios de evaluaci√≥n claros\n- Respuesta modelo de 150-300 palabras con estructura clara\n- Debe incluir definiciones, an√°lisis y ejemplos pr√°cticos'
            },
            'flashcard': {
                'nombre': 'flashcard',
                'puntos': 1,
                'ejemplo': '''{
      "tipo": "flashcard",
      "pregunta": "Concepto o t√©rmino clave",
      "respuesta_correcta": "Definici√≥n o explicaci√≥n",
      "puntos": 1
    }''',
                'instrucciones': '- Pregunta directa sobre un concepto\n- Respuesta concisa y precisa'
            }
        }
        
        info = tipo_info.get(tipo, tipo_info['mcq'])
        
        prompt = f"""Eres un experto en crear ex√°menes educativos. Tu tarea es generar EXACTAMENTE {cantidad} preguntas de tipo "{tipo}" ({info['nombre']}) basadas en el contenido proporcionado.

CONTENIDO A EVALUAR:
{contenido}

üéØ TIPO DE PREGUNTA REQUERIDO: {info['nombre'].upper()}
üìä CANTIDAD EXACTA: {cantidad} preguntas

‚ö†Ô∏è INSTRUCCIONES ESPEC√çFICAS PARA ESTE TIPO:
{info['instrucciones']}

‚ö†Ô∏è REGLAS CR√çTICAS:
1. Genera EXACTAMENTE {cantidad} preguntas de tipo "{tipo}"
2. NO generes otros tipos de preguntas
3. Todas las preguntas deben estar COMPLETAS
4. NO uses placeholders como "...", "[...]"
5. Basa todas las preguntas en el contenido proporcionado
6. Cada pregunta debe ser AUTOCONTENIDA (incluye contexto necesario)
7. NO inventes informaci√≥n que no est√© en el texto

FORMATO JSON (genera un array con {cantidad} preguntas):
{{
  "preguntas": [
    {info['ejemplo']}
  ]
}}

Responde SOLO con JSON v√°lido, sin c√≥digo markdown ni explicaciones adicionales."""

        return prompt
    
    def _crear_prompt(self, contenido: str, num_preguntas: Dict[str, int], total: int, tipo_caso: str = None) -> str:
        """Crea el prompt optimizado
        tipo_caso: Para casos de estudio, especifica el tipo (descriptivo, analitico, resolucion, etc.)
        """
        # Construir lista detallada de tipos de preguntas (USANDO NOMBRES NORMALIZADOS)
        tipos_detalle = []
        if num_preguntas.get('mcq', 0) > 0:
            tipos_detalle.append(f"{num_preguntas['mcq']} de opci√≥n m√∫ltiple (4 opciones A/B/C/D, puntos: 3)")
        if num_preguntas.get('true_false', 0) > 0:
            tipos_detalle.append(f"{num_preguntas['true_false']} verdadero/falso (puntos: 2)")
        if num_preguntas.get('short_answer', 0) > 0:
            tipos_detalle.append(f"{num_preguntas['short_answer']} de respuesta corta (puntos: 3)")
        if num_preguntas.get('cloze', 0) > 0:
            tipos_detalle.append(f"{num_preguntas['cloze']} de relleno de huecos/cloze (texto con {{}}, puntos: 3)")
        if num_preguntas.get('open_question', 0) > 0:
            tipos_detalle.append(f"**üî• {num_preguntas['open_question']} de desarrollo/ensayo EXTENSO** (puntos: 5) - OBLIGATORIO: pregunta compleja que requiere AN√ÅLISIS PROFUNDO")
        
        # Soporte para case_study
        num_casos = num_preguntas.get('case_study', 0)
        if num_casos > 0:
            tipo_desc = f" ({tipo_caso})" if tipo_caso else ""
            tipos_detalle.append(f"{num_casos} caso(s) de estudio{tipo_desc} (puntos: 10)")
        
        tipos_str = "\n".join([f"{i+1}. {t}" for i, t in enumerate(tipos_detalle)])
        
        # Determinar si hay casos de estudio y obtener el prompt espec√≠fico
        caso_estudio_prompt = ""
        if num_casos > 0 and tipo_caso:
            caso_estudio_prompt = self._obtener_prompt_caso_estudio(tipo_caso)
        
        # Formato JSON base (USANDO NOMBRES NORMALIZADOS)
        json_ejemplos = []
        
        # Agregar ejemplos seg√∫n tipos solicitados
        if num_preguntas.get('mcq', 0) > 0:
            json_ejemplos.append("""    {
      "tipo": "mcq",
      "pregunta": "¬øPregunta clara y espec√≠fica sobre el contenido?",
      "opciones": ["A) Primera opci√≥n", "B) Segunda opci√≥n", "C) Tercera opci√≥n", "D) Cuarta opci√≥n"],
      "respuesta_correcta": "A",
      "puntos": 3
    }""")
        
        if num_preguntas.get('true_false', 0) > 0:
            json_ejemplos.append("""    {
      "tipo": "true_false",
      "pregunta": "Afirmaci√≥n clara basada en el contenido",
      "respuesta_correcta": "verdadero",
      "puntos": 2
    }""")
        
        if num_preguntas.get('short_answer', 0) > 0:
            json_ejemplos.append("""    {
      "tipo": "short_answer",
      "pregunta": "Pregunta que requiere una respuesta breve y concreta",
      "respuesta_correcta": "Respuesta esperada (2-3 oraciones)",
      "puntos": 3
    }""")
        
        if num_preguntas.get('cloze', 0) > 0:
            json_ejemplos.append("""    {
      "tipo": "cloze",
      "pregunta": "Python es un lenguaje de {} creado por {} en {}",
      "metadata": {
        "text_with_gaps": "Python es un lenguaje de {} creado por {} en {}",
        "answers": ["programaci√≥n", "Guido van Rossum", "1991"],
        "hint": "Piensa en el tipo de lenguaje y su creador"
      },
      "respuesta_correcta": "programaci√≥n, Guido van Rossum, 1991",
      "puntos": 3
    }""")
        
        if num_preguntas.get('open_question', 0) > 0:
            json_ejemplos.append("""    {
      "tipo": "open_question",
      "pregunta": "Analiza en profundidad [tema complejo del contenido]. Explica los conceptos principales, sus interrelaciones, beneficios/impactos y aplicaciones pr√°cticas. Desarrolla tu respuesta con ejemplos concretos del contenido.",
      "metadata": {
        "key_points": [
          "Definici√≥n y contexto del tema principal",
          "Conceptos o principios fundamentales (m√≠nimo 3)",
          "Relaciones e interconexiones entre conceptos",
          "Beneficios, ventajas o impactos significativos",
          "Aplicaciones pr√°cticas o ejemplos reales",
          "Implicaciones o importancia en el campo"
        ],
        "expected_length": "200-300 palabras",
        "evaluation_criteria": [
          "Profundidad de an√°lisis conceptual",
          "Claridad en explicaciones",
          "Conexi√≥n entre teor√≠a y ejemplos",
          "Estructura l√≥gica y coherencia"
        ]
      },
      "respuesta_correcta": "Respuesta modelo DETALLADA de 200-300 palabras que desarrolle sistem√°ticamente: 1) Definiciones completas de conceptos clave con contexto del contenido, 2) An√°lisis de c√≥mo se relacionan e interconectan estos conceptos (m√≠nimo 3 relaciones explicadas), 3) Explicaci√≥n de beneficios o impactos significativos con datos/evidencia del texto, 4) Ejemplos concretos y espec√≠ficos extra√≠dos del contenido, 5) Aplicaciones pr√°cticas en contextos reales, 6) Reflexi√≥n sobre importancia o implicaciones. La respuesta debe demostrar comprensi√≥n profunda, no superficial.",
      "puntos": 5
    }""")
        
        # Soporte para case_study
        if num_casos > 0:
            json_ejemplos.append(caso_estudio_prompt)
        
        json_ejemplos_str = ",\n".join(json_ejemplos)
        
        return f"""Eres un experto en crear ex√°menes educativos. Tu tarea es generar EXACTAMENTE {total} preguntas REALES basadas en el contenido proporcionado.

CONTENIDO A EVALUAR:
{contenido}

üî• DISTRIBUCI√ìN OBLIGATORIA - GENERA {total} PREGUNTAS ASI:
{tipos_str}

‚ö†Ô∏è ATENCI√ìN ESPECIAL: Si la distribuci√≥n incluye "open_question", "caso de estudio" o "desarrollo", DEBES generarla. Son los tipos m√°s importantes.

‚ö†Ô∏è REGLAS CR√çTICAS - LEE CON ATENCI√ìN:
1. Genera EXACTAMENTE {total} preguntas COMPLETAS con contenido REAL
2. RESPETA LA DISTRIBUCI√ìN DE TIPOS especificada arriba - CADA TIPO ES OBLIGATORIO
3. Los tipos v√°lidos son: "mcq", "true_false", "short_answer", "open_question", "case_study"
4. Para "case_study": DEBES incluir TODOS los campos del formato especificado arriba (contexto, descripcion, etc.)
5. NO uses placeholders como "...", "[...]", "puntos: ..."
6. NO REPITAS preguntas - cada una debe ser √öNICA con texto diferente
7. ‚ö†Ô∏è IMPORTANTE: Cada pregunta debe ser AUTOCONTENIDA - incluye el contexto necesario en el texto de la pregunta
   - En lugar de: "¬øC√≥mo utiliza el dise√±o gr√°fico esta ley?" ‚Üí "¬øC√≥mo utiliza el dise√±o gr√°fico la Ley de Continuidad de Gestalt?"
   - En lugar de: "¬øQu√© significa esto?" ‚Üí "¬øQu√© significa el t√©rmino 'dise√±o basado en valores'?"
   - La pregunta debe entenderse SIN necesidad de ver el contenido original
8. CADA pregunta debe estar COMPLETAMENTE llena con:
   - "tipo": uno de estos valores exactos: "mcq", "true_false", "short_answer", "open_question", "case_study"
   - "pregunta": texto completo y autocontenido de la pregunta (m√≠nimo 10 palabras, con contexto incluido)
   - Para "mcq": "opciones" debe ser un array de 4 strings completos (ej: ["A) opci√≥n real 1", "B) opci√≥n real 2", "C) opci√≥n real 3", "D) opci√≥n real 4"])
   - "respuesta_correcta": la respuesta correcta REAL (para MCQ: letra A/B/C/D, para otros: texto completo)
   - "puntos": n√∫mero entero (3 para mcq, 2 para true_false, 3 para short_answer, 5 para open_question, 10 para case_study)
9. Todas las preguntas deben basarse en informaci√≥n del contenido proporcionado
10. NO inventes informaci√≥n que no est√© en el texto
11. Responde SOLO con JSON v√°lido, sin c√≥digo markdown, sin explicaciones adicionales

FORMATO JSON V√ÅLIDO (con datos REALES, NO placeholders):
{{
  "preguntas": [
    {{
      "tipo": "mcq",
      "pregunta": "¬øSeg√∫n el contenido, cu√°l es la diferencia principal entre arte y dise√±o?",
      "opciones": ["A) El arte es un sustantivo y el dise√±o es un verbo", "B) No hay diferencia", "C) El arte es comercial", "D) El dise√±o no comunica"],
      "respuesta_correcta": "A",
      "puntos": 3
    }},
    {{
      "tipo": "short_answer",
      "pregunta": "Explica brevemente qu√© significa HCI seg√∫n la clase",
      "respuesta_correcta": "HCI significa Human-Computer Interaction (Interacci√≥n Humano-Computadora), que estudia c√≥mo las personas interact√∫an con la tecnolog√≠a",
      "puntos": 3
    }}
  ]
}}

üî• RECORDATORIO FINAL: Si la distribuci√≥n arriba especifica "open_question", debes incluirla obligatoriamente en tu respuesta JSON.

AHORA GENERA LAS {total} PREGUNTAS COMPLETAS CON DATOS REALES (recuerda incluir TODOS los tipos solicitados):"""
    
    def _obtener_prompt_caso_estudio(self, tipo_caso: str) -> str:
        """Retorna el formato JSON espec√≠fico para cada tipo de caso de estudio
        
        IMPORTANTE: Los casos de estudio requieren MUCHO M√ÅS DETALLE que otros tipos de preguntas.
        - El contexto debe tener al menos 3-5 oraciones (100-200 palabras)
        - La descripci√≥n debe tener al menos 4-6 oraciones (150-300 palabras)
        - Todos los arrays deben tener 4-6 elementos detallados
        """
    
    def _filtrar_preguntas(self, preguntas: List[PreguntaExamen], num_preguntas: Dict[str, int]) -> List[PreguntaExamen]:
        """Filtra preguntas por tipo y cantidad solicitada
        
        ESTRATEGIA DE FILTRADO:
        1. Prioriza cumplir con las cantidades exactas por tipo
        2. Si faltan algunos tipos, incluye extras de otros tipos hasta alcanzar el total solicitado
        """
        preguntas_filtradas = []
        contador_por_tipo = {}
        preguntas_sobrantes = []
        
        # Mapeo de tipos nuevos a tipos del sistema
        mapeo_tipos = {
            'flashcard': 'flashcard',
            'mcq': 'mcq', 
            'true_false': 'true_false',
            'verdadero_falso': 'true_false',
            'verdadero-falso': 'true_false',
            'cloze': 'cloze',
            'short_answer': 'short_answer',
            'respuesta_corta': 'short_answer',
            'open_question': 'open_question',
            'desarrollo': 'open_question',
            'case_study': 'case_study',
            'caso_estudio': 'case_study',
            'reading_comprehension': 'reading_comprehension',
            'reading_true_false': 'reading_true_false',
            'reading_cloze': 'reading_cloze',
            'reading_skill': 'reading_skill',
            'reading_matching': 'reading_matching',
            'reading_sequence': 'reading_sequence',
            'writing_short': 'writing_short',
            'writing_paraphrase': 'writing_paraphrase',
            'writing_correction': 'writing_correction',
            'writing_transformation': 'writing_transformation',
            'writing_essay': 'writing_essay',
            'writing_sentence_builder': 'writing_sentence_builder',
            'writing_picture_description': 'writing_picture_description',
            'writing_email': 'writing_email',
            'multiple': 'mcq',
            'corta': 'short_answer'
        }
        
        # FASE 1: Seleccionar preguntas seg√∫n cantidades solicitadas por tipo
        for pregunta in preguntas:
            # DEBUG: Imprimir tipo exacto de la pregunta
            print(f"  üîç Pregunta tipo='{pregunta.tipo}' (repr: {repr(pregunta.tipo)})")
            tipo_normalizado = mapeo_tipos.get(pregunta.tipo, pregunta.tipo)
            print(f"     ‚Üí Normalizado a: '{tipo_normalizado}'")
            
            # üî• L√ìGICA ESPECIAL: Si generamos open_question pero se solicit√≥ case_study, aceptarla
            # Esto maneja el caso donde el modelo no genera el formato completo de case_study
            if tipo_normalizado == 'open_question' and num_preguntas.get('case_study', 0) > 0:
                # Si hay case_study solicitados y no se han cumplido, usar esta open_question
                if contador_por_tipo.get('case_study', 0) < num_preguntas.get('case_study', 0):
                    tipo_normalizado = 'case_study'
                    print(f"     ‚Üí üîÑ Reasignado a case_study (case_study solicitados no cumplidos)")
            
            cantidad_solicitada = num_preguntas.get(tipo_normalizado, 0)
            print(f"     ‚Üí Cantidad solicitada de '{tipo_normalizado}': {cantidad_solicitada}")
            
            if cantidad_solicitada > 0:
                if tipo_normalizado not in contador_por_tipo:
                    contador_por_tipo[tipo_normalizado] = 0
                
                if contador_por_tipo[tipo_normalizado] < cantidad_solicitada:
                    preguntas_filtradas.append(pregunta)
                    contador_por_tipo[tipo_normalizado] += 1
                else:
                    # Guardar extras para usar si faltan otros tipos
                    preguntas_sobrantes.append(pregunta)
        
        # Calcular total esperado
        total_esperado = sum(num_preguntas.values())
        total_actual = len(preguntas_filtradas)
        
        # FASE 2: Si faltan preguntas, agregar extras hasta completar el total
        if total_actual < total_esperado and preguntas_sobrantes:
            faltantes = total_esperado - total_actual
            print(f"‚ö†Ô∏è Faltan {faltantes} preguntas. Agregando extras de otros tipos...")
            
            for i, pregunta_extra in enumerate(preguntas_sobrantes):
                if len(preguntas_filtradas) >= total_esperado:
                    break
                preguntas_filtradas.append(pregunta_extra)
                tipo_norm = mapeo_tipos.get(pregunta_extra.tipo, pregunta_extra.tipo)
                contador_por_tipo[tipo_norm] = contador_por_tipo.get(tipo_norm, 0) + 1
                print(f"   ‚ûï Agregada pregunta extra #{i+1} (tipo: {tipo_norm})")
        
        print(f"üîç Filtrado: {len(preguntas)} generadas ‚Üí {len(preguntas_filtradas)} retornadas (esperadas: {total_esperado})")
        print(f"   Solicitadas: {num_preguntas}")
        print(f"   Filtradas por tipo: {contador_por_tipo}")
        
        # Registrar filtrado
        self._agregar_log('filtrado', {
            'total_generadas': len(preguntas),
            'total_filtradas': len(preguntas_filtradas),
            'total_esperado': total_esperado,
            'solicitadas': num_preguntas,
            'contador_por_tipo': contador_por_tipo
        })
        
        # Verificar si faltaron preguntas
        tipos_faltantes = []
        for tipo, cantidad in num_preguntas.items():
            generadas = contador_por_tipo.get(tipo, 0)
            if generadas < cantidad:
                tipos_faltantes.append(f"{tipo}: {generadas}/{cantidad}")
        
        if tipos_faltantes:
            warning_msg = f"El modelo no gener√≥ suficientes preguntas: {', '.join(tipos_faltantes)}"
            self._agregar_log('errores', warning_msg)
            print(f"‚ö†Ô∏è ADVERTENCIA: El modelo no gener√≥ suficientes preguntas de algunos tipos:")
            for faltante in tipos_faltantes:
                tipo_falt = faltante.split(':')[0].strip()
                print(f"   - {faltante}")
            
            if len(preguntas_filtradas) < total_esperado:
                print(f"   Esto puede ocurrir porque:")
                print(f"   1. El modelo gener√≥ tipos diferentes a los solicitados")
                print(f"   2. El modelo ignor√≥ las instrucciones del prompt")
                print(f"   3. El contenido es muy corto para generar m√°s preguntas")
                print(f"   üí° Intenta regenerar la pr√°ctica")
            else:
                print(f"   ‚úÖ Se compens√≥ con extras: {len(preguntas_filtradas)}/{total_esperado} preguntas retornadas")
        
        return preguntas_filtradas
    
    def _obtener_prompt_caso_estudio(self, tipo_caso: str) -> str:
        """Retorna el formato JSON espec√≠fico para cada tipo de caso de estudio
        
        IMPORTANTE: Los casos de estudio requieren MUCHO M√ÅS DETALLE que otros tipos de preguntas.
        - El contexto debe tener al menos 3-5 oraciones (100-200 palabras)
        - La descripci√≥n debe tener al menos 4-6 oraciones (150-300 palabras)
        - Todos los arrays deben tener 4-6 elementos detallados
        """
        
        formatos_casos = {
            "descriptivo": """    {
      "tipo": "case_study",
      "subtipo": "descriptivo",
      "titulo": "T√≠tulo descriptivo del caso (m√°x 10 palabras)",
      "contexto": "CONTEXTO DETALLADO (m√≠nimo 100 palabras): Situaci√≥n completa del caso con fecha, lugar, personas involucradas, empresa/organizaci√≥n, industria, antecedentes hist√≥ricos y estado inicial. Describe el escenario completo para que el estudiante entienda el panorama general.",
      "descripcion": "DESCRIPCI√ìN EXHAUSTIVA (m√≠nimo 150 palabras): Descripci√≥n muy detallada de todos los eventos cronol√≥gicamente, personas clave con sus roles, decisiones tomadas con justificaciones, acciones realizadas, resultados obtenidos, reacciones de stakeholders, m√©tricas relevantes, cambios observados. Incluye datos espec√≠ficos, n√∫meros, porcentajes cuando sea posible.",
      "pregunta": "Pregunta espec√≠fica que requiere identificar y analizar los elementos clave que caracterizaron esta situaci√≥n",
      "puntos_clave": ["Punto clave 1 con detalles espec√≠ficos", "Punto clave 2 con contexto", "Punto clave 3 con implicaciones", "Punto clave 4 con evidencia", "Punto clave 5 para an√°lisis profundo"],
      "respuesta_esperada": "An√°lisis descriptivo esperado (m√≠nimo 100 palabras) de los elementos principales del caso con observaciones, s√≠ntesis y entendimiento del contexto",
      "puntos": 10
    }""",
            
            "analitico": """    {
      "tipo": "case_study",
      "subtipo": "analitico",
      "titulo": "T√≠tulo del caso anal√≠tico (m√°x 10 palabras)",
      "contexto": "CONTEXTO DETALLADO (m√≠nimo 100 palabras): Situaci√≥n empresarial, t√©cnica o de negocio completa con antecedentes, estado actual, m√©tricas relevantes, actores involucrados, mercado, competencia, recursos disponibles. Proporciona todos los elementos necesarios para un an√°lisis profundo.",
      "descripcion": "DESCRIPCI√ìN EXHAUSTIVA (m√≠nimo 150 palabras): Descripci√≥n completa de la problem√°tica incluyendo datos cuantitativos y cualitativos, tendencias observadas, se√±ales de alerta, informaci√≥n hist√≥rica, comparativas con per√≠odos anteriores, feedback de usuarios/clientes, m√©tricas de rendimiento, puntos de fricci√≥n identificados. S√© muy espec√≠fico con n√∫meros y fechas.",
      "pregunta": "Analiza en profundidad las causas ra√≠z, las relaciones causales entre factores y las consecuencias directas e indirectas de esta situaci√≥n",
      "areas_analisis": ["Causas principales con evidencia espec√≠fica", "Relaciones causales entre factores A y B", "Consecuencias inmediatas observadas", "Impacto a mediano plazo en X √°rea", "Impacto a largo plazo en sostenibilidad", "Factores externos que influyeron"],
      "respuesta_esperada": "An√°lisis profundo (m√≠nimo 150 palabras) de causas-efectos con relaciones causales claramente identificadas, evidencia para cada afirmaci√≥n y conclusiones fundamentadas",
      "puntos": 10
    }""",
            
            "resolucion": """    {
      "tipo": "case_study",
      "subtipo": "resolucion",
      "titulo": "T√≠tulo del problema (m√°x 10 palabras)",
      "contexto": "CONTEXTO DETALLADO (m√≠nimo 100 palabras): Situaci√≥n problem√°tica completa con antecedentes de c√≥mo surgi√≥ el problema, qui√©nes est√°n afectados, desde cu√°ndo existe, intentos previos de soluci√≥n, estado cr√≠tico actual, urgencia del problema, recursos disponibles para resolverlo.",
      "descripcion": "DESCRIPCI√ìN EXHAUSTIVA (m√≠nimo 150 palabras): Detalles completos del problema incluyendo s√≠ntomas espec√≠ficos, impacto cuantificado en m√©tricas de negocio, afectaci√≥n a diferentes stakeholders, costos del problema, riesgos si no se resuelve, interdependencias con otros sistemas/procesos, evidencia documental del problema, quejas espec√≠ficas recibidas.",
      "pregunta": "Prop√≥n una soluci√≥n viable, detallada y pr√°ctica para resolver este problema considerando todas las restricciones",
      "restricciones": ["Restricci√≥n presupuestaria: m√°ximo $X disponible", "Restricci√≥n de tiempo: debe resolverse en Y semanas", "Restricci√≥n t√©cnica: compatibilidad con sistema Z", "Restricci√≥n de recursos humanos: solo N personas disponibles", "Restricci√≥n regulatoria: cumplir norma ABC"],
      "criterios_evaluacion": ["Viabilidad t√©cnica y factibilidad", "Relaci√≥n costo-beneficio y ROI esperado", "Facilidad y rapidez de implementaci√≥n", "Impacto positivo medible en m√©tricas clave", "Sostenibilidad a largo plazo", "Aceptaci√≥n de stakeholders"],
      "respuesta_esperada": "Soluci√≥n detallada (m√≠nimo 150 palabras) con pasos concretos numerados, cronograma estimado, recursos necesarios, responsables, KPIs de √©xito y justificaci√≥n de por qu√© esta soluci√≥n es la √≥ptima",
      "puntos": 10
    }""",
            
            "decision": """    {
      "tipo": "case_study",
      "subtipo": "decision",
      "titulo": "T√≠tulo de la decisi√≥n cr√≠tica (m√°x 10 palabras)",
      "contexto": "CONTEXTO DETALLADO (m√≠nimo 100 palabras): Escenario completo donde se requiere tomar una decisi√≥n cr√≠tica con impacto significativo. Incluye antecedentes de la situaci√≥n, presiones externas, plazos l√≠mite, stakeholders con sus intereses conflictivos, recursos disponibles, informaci√≥n conocida e incertidumbres.",
      "descripcion": "DESCRIPCI√ìN EXHAUSTIVA (m√≠nimo 150 palabras): Detalles completos del escenario de decisi√≥n incluyendo qui√©nes son todos los stakeholders afectados y sus intereses espec√≠ficos, qu√© opciones est√°n disponibles con sus caracter√≠sticas principales, cu√°les son los trade-offs entre opciones, qu√© informaci√≥n falta, cu√°les son los riesgos de cada camino, precedentes hist√≥ricos de decisiones similares, presiones pol√≠ticas/sociales.",
      "pregunta": "¬øQu√© decisi√≥n tomar√≠as entre las opciones disponibles y por qu√© es la mejor opci√≥n considerando todos los factores?",
      "opciones_disponibles": ["Opci√≥n A: descripci√≥n detallada de esta alternativa con pros, contras y consecuencias esperadas", "Opci√≥n B: descripci√≥n completa de segunda alternativa con impactos cuantificados", "Opci√≥n C: tercera alternativa con an√°lisis de viabilidad", "Opci√≥n D: cuarta opci√≥n con riesgos asociados"],
      "criterios_decision": ["Impacto financiero a corto y largo plazo", "Alineaci√≥n con objetivos estrat√©gicos", "Riesgos y mitigaciones posibles", "Tiempo de implementaci√≥n requerido", "Aceptaci√≥n de stakeholders clave", "Sostenibilidad y escalabilidad"],
      "respuesta_esperada": "Decisi√≥n justificada (m√≠nimo 150 palabras) con an√°lisis detallado de pros y contras de cada opci√≥n, razonamiento l√≥gico, evidencia que soporta la decisi√≥n, plan de mitigaci√≥n de riesgos y criterios de √©xito",
      "puntos": 10
    }""",
            
            "comparativo": """    {
      "tipo": "case_study",
      "subtipo": "comparativo",
      "titulo": "T√≠tulo de la comparaci√≥n (m√°x 10 palabras)",
      "contexto": "CONTEXTO DETALLADO (m√≠nimo 100 palabras): Situaci√≥n que presenta m√∫ltiples alternativas a comparar con antecedentes de cada una, mercado/industria donde se aplican, casos de √©xito y fracaso previos, tendencias actuales, necesidades espec√≠ficas del caso de uso.",
      "descripcion": "DESCRIPCI√ìN EXHAUSTIVA (m√≠nimo 150 palabras): Detalles completos de cada alternativa incluyendo caracter√≠sticas t√©cnicas espec√≠ficas, ventajas y desventajas documentadas, costos detallados (inicial, operativo, mantenimiento), requisitos de implementaci√≥n, curva de aprendizaje, soporte disponible, casos de uso recomendados, limitaciones conocidas.",
      "pregunta": "Compara cr√≠ticamente todas las alternativas presentadas utilizando los criterios especificados y recomienda la mejor opci√≥n",
      "elementos_comparar": {
        "alternativa_1": {"nombre": "Nombre de alternativa 1", "caracteristicas": ["Caracter√≠stica t√©cnica 1 con detalles", "Caracter√≠stica 2 con m√©tricas", "Ventaja competitiva espec√≠fica", "Limitaci√≥n identificada", "Caso de uso ideal"]},
        "alternativa_2": {"nombre": "Nombre de alternativa 2", "caracteristicas": ["Caracter√≠stica t√©cnica 1 con detalles", "Caracter√≠stica 2 con m√©tricas", "Ventaja competitiva espec√≠fica", "Limitaci√≥n identificada", "Caso de uso ideal"]},
        "alternativa_3": {"nombre": "Nombre de alternativa 3", "caracteristicas": ["Caracter√≠stica t√©cnica 1 con detalles", "Caracter√≠stica 2 con m√©tricas", "Ventaja competitiva espec√≠fica", "Limitaci√≥n identificada", "Caso de uso ideal"]}
      },
      "criterios_comparacion": ["Rendimiento medible en benchmarks", "Costo total de propiedad (TCO)", "Facilidad de uso y curva de aprendizaje", "Escalabilidad y capacidad de crecimiento", "Soporte y ecosistema disponible", "Madurez y estabilidad de la soluci√≥n"],
      "respuesta_esperada": "Comparaci√≥n detallada (m√≠nimo 150 palabras) con matriz comparativa, evaluaci√≥n cr√≠tica de cada alternativa contra cada criterio, recomendaci√≥n fundamentada y escenarios donde cada opci√≥n ser√≠a la mejor",
      "puntos": 10
    }""",
            
            "predictivo": """    {
      "tipo": "case_study",
      "subtipo": "predictivo",
      "titulo": "T√≠tulo del escenario predictivo (m√°x 10 palabras)",
      "contexto": "CONTEXTO DETALLADO (m√≠nimo 100 palabras): Situaci√≥n actual completa con datos hist√≥ricos de los √∫ltimos meses/a√±os, tendencias observadas con gr√°ficas impl√≠citas, m√©tricas actuales con valores espec√≠ficos, indicadores clave de rendimiento, comparativas con per√≠odos anteriores, factores externos que est√°n influyendo.",
      "descripcion": "DESCRIPCI√ìN EXHAUSTIVA (m√≠nimo 150 palabras): Datos actuales muy espec√≠ficos incluyendo m√©tricas cuantitativas con n√∫meros exactos, tasas de crecimiento/decrecimiento observadas, patrones identificados en series de tiempo, eventos recientes que han impactado, se√±ales del mercado, comportamiento de la competencia, cambios en regulaciones, tendencias macroecon√≥micas, feedback de clientes/usuarios con estad√≠sticas.",
      "pregunta": "Bas√°ndote en los datos actuales y tendencias, proyecta el comportamiento futuro de esta situaci√≥n en los pr√≥ximos 6-12 meses",
      "datos_actuales": ["M√©trica 1: valor actual con % de cambio vs mes anterior", "Indicador 2: cifra espec√≠fica con tendencia observada", "KPI 3: n√∫mero actual con hist√≥rico de 3 meses", "Variable 4: dato cuantitativo con proyecci√≥n lineal", "Factor externo 5: impacto medido en la m√©trica principal"],
      "factores_considerar": ["Factor econ√≥mico externo con impacto estimado", "Variable de mercado con probabilidad de cambio", "Riesgo identificado con nivel de severidad", "Oportunidad potencial con timeframe", "Tendencia tecnol√≥gica con adopci√≥n esperada", "Cambio regulatorio con fecha de implementaci√≥n"],
      "respuesta_esperada": "Predicci√≥n fundamentada (m√≠nimo 150 palabras) con proyecciones num√©ricas espec√≠ficas, evidencia estad√≠stica que soporta la predicci√≥n, an√°lisis de tendencias, escenarios alternativos (optimista/realista/pesimista) y justificaci√≥n matem√°tica o l√≥gica del pron√≥stico",
      "puntos": 10
    }""",
            
            "simulacion": """    {
      "tipo": "case_study",
      "subtipo": "simulacion",
      "titulo": "T√≠tulo de la simulaci√≥n (m√°x 10 palabras)",
      "contexto": "CONTEXTO DETALLADO (m√≠nimo 100 palabras): Descripci√≥n completa del mundo simulado incluyendo reglas del sistema, objetivo general del simulacro, condiciones iniciales del escenario, recursos disponibles al inicio, restricciones del entorno, mec√°nicas de funcionamiento, c√≥mo interact√∫an las variables entre s√≠.",
      "descripcion": "DESCRIPCI√ìN EXHAUSTIVA (m√≠nimo 150 palabras): Descripci√≥n detallada del sistema completo incluyendo todas las reglas de operaci√≥n, c√≥mo cada variable afecta a las dem√°s (interdependencias), qu√© acciones est√°n permitidas, cu√°les son los l√≠mites del sistema, qu√© eventos aleatorios pueden ocurrir, c√≥mo se mide el √©xito, consecuencias de buenas y malas decisiones.",
      "pregunta": "Toma una secuencia de decisiones estrat√©gicas en este escenario simulado, justificando cada elecci√≥n bas√°ndote en el estado actual del sistema",
      "variables_dinamicas": {
        "variable_1": {"nombre": "Nombre descriptivo de variable 1", "valor_inicial": 100, "rango": "0-200", "descripcion": "Qu√© representa esta variable y c√≥mo impacta el sistema"},
        "variable_2": {"nombre": "Nombre de variable 2", "valor_inicial": "medio", "opciones": ["bajo", "medio", "alto"], "descripcion": "Significado de cada nivel y sus efectos"},
        "variable_3": {"nombre": "Variable 3", "valor_inicial": 50, "rango": "0-100", "descripcion": "Relaci√≥n con otras variables y thresholds cr√≠ticos"}
      },
      "decisiones_tomar": ["Decisi√≥n 1: descripci√≥n detallada de qu√© hay que decidir y qu√© opciones existen", "Decisi√≥n 2: contexto espec√≠fico y timing de esta decisi√≥n", "Decisi√≥n 3: trade-offs involucrados y consecuencias esperadas", "Decisi√≥n 4: dependencias con decisiones anteriores"],
      "respuesta_esperada": "Secuencia de decisiones (m√≠nimo 150 palabras) con justificaci√≥n detallada basada en el estado simulado del sistema, an√°lisis de c√≥mo cada decisi√≥n afecta las variables, predicci√≥n de outcomes, y estrategia global coherente",
      "puntos": 10
    }""",
            
            "inverso": """    {
      "tipo": "case_study",
      "subtipo": "inverso",
      "titulo": "T√≠tulo del caso inverso (m√°x 10 palabras)",
      "contexto": "CONTEXTO DETALLADO (m√≠nimo 100 palabras): Resultado final conocido con descripci√≥n completa del outcome obtenido, cu√°ndo ocurri√≥, qui√©nes estuvieron involucrados, qu√© se logr√≥ exactamente con m√©tricas espec√≠ficas, estado inicial conocido vs estado final, informaci√≥n disponible sobre el proceso.",
      "descripcion": "DESCRIPCI√ìN EXHAUSTIVA (m√≠nimo 150 palabras): Descripci√≥n muy detallada del resultado final incluyendo todas las caracter√≠sticas observables, m√©tricas de √©xito alcanzadas con n√∫meros espec√≠ficos, evidencias documentadas del outcome, comparaci√≥n con objetivos iniciales, impacto medible del resultado, testimonios o feedback disponible, documentaci√≥n existente del resultado.",
      "pregunta": "Trabajando hacia atr√°s desde el resultado final conocido, reconstruye el proceso l√≥gico que probablemente se sigui√≥ para llegar a este outcome",
      "resultado_final": "DESCRIPCI√ìN DETALLADA (m√≠nimo 80 palabras) del outcome final alcanzado con todas las m√©tricas, caracter√≠sticas, atributos, impactos medibles, evidencias concretas del √©xito o fracaso del resultado",
      "pistas": ["Pista 1: evidencia espec√≠fica encontrada con detalles", "Pista 2: dato conocido del proceso con contexto", "Pista 3: testimonio o documento que revela informaci√≥n", "Pista 4: patr√≥n observado en el resultado", "Pista 5: inconsistencia o anomal√≠a que da informaci√≥n"],
      "pasos_reconstruir": 5,
      "respuesta_esperada": "Reconstrucci√≥n l√≥gica (m√≠nimo 150 palabras) del proceso paso a paso con justificaci√≥n detallada de por qu√© cada paso fue necesario, evidencia que soporta cada etapa deducida, razonamiento l√≥gico de la secuencia, y validaci√≥n de que el proceso reconstruido llevar√≠a al resultado observado",
      "puntos": 10
    }""",
            
            "fallo": """    {
      "tipo": "case_study",
      "subtipo": "fallo",
      "titulo": "T√≠tulo del desastre/fallo (m√°x 10 palabras)",
      "contexto": "CONTEXTO DETALLADO (m√≠nimo 100 palabras): Situaci√≥n previa al fallo con antecedentes de qu√© se estaba intentando lograr, qui√©nes estaban involucrados, objetivos iniciales con m√©tricas esperadas, recursos invertidos, expectativas del mercado/stakeholders, presiones existentes, timeline del proyecto/iniciativa.",
      "descripcion": "DESCRIPCI√ìN EXHAUSTIVA (m√≠nimo 150 palabras): Descripci√≥n completa del fallo incluyendo cronolog√≠a detallada de eventos que llevaron al desastre, qu√© espec√≠ficamente sali√≥ mal con evidencia concreta, cu√°ndo se manifest√≥ el problema por primera vez, c√≥mo escal√≥, qu√© intentos de correcci√≥n fallaron, magnitud del fracaso con n√∫meros (p√©rdidas, impacto), reacciones de stakeholders, cobertura medi√°tica si aplica.",
      "pregunta": "Analiza en profundidad qu√© caus√≥ este fallo, identifica las se√±ales de alerta ignoradas y prop√≥n c√≥mo se pudo haber prevenido o mitigado",
      "se√±ales_alerta": ["Se√±al de alerta 1 ignorada: descripci√≥n espec√≠fica de qu√© warning se pas√≥ por alto y cu√°ndo", "Warning sign 2: indicador espec√≠fico que mostr√≥ problemas con timeline", "Red flag 3: evidencia de riesgo que no se atendi√≥ con consecuencias", "Alerta temprana 4: persona o sistema que alert√≥ sin ser escuchado"],
      "consecuencias": ["Consecuencia 1: impacto espec√≠fico con m√©trica cuantificada (ej: p√©rdida de $X millones)", "Impacto 2: efecto en stakeholders con descripci√≥n detallada", "P√©rdida 3: activo o recurso perdido con valoraci√≥n", "Da√±o reputacional 4: impacto en imagen con evidencia", "Consecuencia legal 5: demandas o sanciones enfrentadas"],
      "respuesta_esperada": "An√°lisis exhaustivo (m√≠nimo 150 palabras) de causas ra√≠z del fallo con evidencia espec√≠fica, identificaci√≥n de errores de proceso/juicio, lecciones aprendidas documentadas, medidas de prevenci√≥n concretas para evitar fallos similares en el futuro, y checklist de early warnings",
      "puntos": 10
    }""",
            
            "creativo": """    {
      "tipo": "case_study",
      "subtipo": "creativo",
      "titulo": "T√≠tulo del reto creativo (m√°x 10 palabras)",
      "contexto": "CONTEXTO DETALLADO (m√≠nimo 100 palabras): Situaci√≥n completa que requiere innovaci√≥n incluyendo estado actual del mercado/industria, necesidad identificada con evidencia de demanda, soluciones existentes y sus limitaciones, oportunidad de innovaci√≥n con tama√±o de mercado potencial, tendencias que favorecen la innovaci√≥n, casos inspiradores de innovaciones similares.",
      "descripcion": "DESCRIPCI√ìN EXHAUSTIVA (m√≠nimo 150 palabras): Descripci√≥n detallada del desaf√≠o u oportunidad de innovaci√≥n incluyendo pain points espec√≠ficos de usuarios/clientes con evidencia cualitativa, gaps en soluciones actuales con ejemplos concretos, restricciones tecnol√≥gicas o de mercado, barreras de entrada, ventana de oportunidad, stakeholders que se beneficiar√≠an, recursos disponibles para innovar.",
      "pregunta": "Prop√≥n una soluci√≥n creativa, original e innovadora para este desaf√≠o que sea viable y tenga alto potencial de impacto",
      "restricciones": ["Restricci√≥n presupuestaria: m√°ximo $X para desarrollo inicial", "Limitaci√≥n tecnol√≥gica: debe ser compatible con Y", "Constraint de tiempo: lanzamiento en Z meses", "Restricci√≥n regulatoria: debe cumplir con norma ABC", "Limitaci√≥n de recursos: equipo de N personas disponible"],
      "criterios_creatividad": ["Originalidad: qu√© tan novedosa es la idea vs soluciones existentes", "Viabilidad t√©cnica: puede construirse con tecnolog√≠a actual", "Impacto potencial: tama√±o del problema resuelto y beneficio generado", "Innovaci√≥n disruptiva: cambia paradigmas o crea nuevos mercados", "Escalabilidad: puede crecer sin multiplicar costos linealmente", "User experience: qu√© tan intuitiva y deseabl e es la soluci√≥n"],
      "respuesta_esperada": "Idea innovadora (m√≠nimo 150 palabras) con descripci√≥n detallada de c√≥mo funciona, qu√© problema resuelve espec√≠ficamente, por qu√© es diferente de lo existente, justificaci√≥n de viabilidad t√©cnica, an√°lisis de mercado potencial, mockups o ejemplos conceptuales, y plan de validaci√≥n de la idea",
      "puntos": 10
    }""",
            
            "etico": """    {
      "tipo": "case_study",
      "subtipo": "etico",
      "titulo": "T√≠tulo del dilema √©tico (m√°x 10 palabras)",
      "contexto": "CONTEXTO DETALLADO (m√≠nimo 100 palabras): Situaci√≥n completa donde surge el conflicto √©tico incluyendo antecedentes de la empresa/organizaci√≥n, presiones de negocio espec√≠ficas, stakeholders involucrados con sus intereses, marco regulatorio aplicable, precedentes de casos similares, cultura organizacional, valores declarados vs pr√°cticas reales.",
      "descripcion": "DESCRIPCI√ìN EXHAUSTIVA (m√≠nimo 150 palabras): Descripci√≥n completa del conflicto entre beneficio empresarial y consideraciones √©ticas/morales incluyendo n√∫meros espec√≠ficos de impacto financiero, qui√©nes se benefician vs qui√©nes se perjudican, consecuencias legales potenciales, impacto reputacional, presi√≥n de competidores, expectativas de accionistas, opini√≥n p√∫blica, evidencia de casos similares.",
      "pregunta": "¬øQu√© decisi√≥n es la correcta balanceando perspectivas √©ticas, legales y empresariales? Justifica tu posici√≥n considerando todos los stakeholders",
      "stakeholders": ["Stakeholder 1: descripci√≥n del grupo con sus intereses espec√≠ficos y poder de influencia", "Parte interesada 2: qui√©nes son y qu√© ganan/pierden en cada escenario", "Grupo afectado 3: impacto directo en su bienestar con detalle", "Stakeholder 4: expectativas y poder de presi√≥n que ejercen", "Parte 5: derechos que est√°n en juego"],
      "dilema": "DILEMA ESPEC√çFICO (m√≠nimo 50 palabras): Descripci√≥n detallada del conflicto √©tico espec√≠fico con las dos o m√°s opciones mutuamente excluyentes, qu√© valores entran en conflicto, qu√© principios √©ticos est√°n en tensi√≥n, ejemplos concretos del trade-off",
      "consideraciones_eticas": ["Principio √©tico 1: explicaci√≥n de qu√© norma moral aplica y c√≥mo", "Valor 2: qu√© valor fundamental est√° en juego con justificaci√≥n", "Norma moral 3: est√°ndar √©tico relevante de la industria o sociedad", "Framework √©tico 4: lente de an√°lisis (utilitarismo, deontolog√≠a, √©tica de virtudes)", "Precedente 5: casos hist√≥ricos similares y sus resoluciones"],
      "respuesta_esperada": "Decisi√≥n fundamentada (m√≠nimo 150 palabras) balanceando √©tica, legalidad y necesidades del negocio con an√°lisis de consecuencias de cada opci√≥n, framework √©tico aplicado, justificaci√≥n moral robusta, consideraci√≥n de todos los stakeholders, y plan de implementaci√≥n que minimice da√±os",
      "puntos": 10
    }""",
            
            "tecnico": """    {
      "tipo": "case_study",
      "subtipo": "tecnico",
      "titulo": "T√≠tulo del caso t√©cnico (m√°x 10 palabras)",
      "contexto": "CONTEXTO DETALLADO (m√≠nimo 100 palabras): Descripci√≥n completa del sistema, algoritmo o proceso t√©cnico actual incluyendo arquitectura general, tecnolog√≠as utilizadas, escala de operaci√≥n, volumetr√≠a de datos procesados, usuarios concurrentes, infraestructura donde corre, historial de performance, evoluci√≥n del sistema en el tiempo.",
      "descripcion": "DESCRIPCI√ìN EXHAUSTIVA (m√≠nimo 150 palabras): Descripci√≥n t√©cnica completa del sistema incluyendo componentes espec√≠ficos con sus versiones, flujo de datos detallado, integraciones existentes, m√©tricas de rendimiento actuales con n√∫meros exactos (latencia P95, throughput, error rate), cuellos de botella identificados con evidencia de profiling, limitaciones de la arquitectura actual, deuda t√©cnica acumulada, incidentes recientes relacionados con performance.",
      "pregunta": "Optimiza este sistema t√©cnico mejorando significativamente su rendimiento mientras mantienes o reduces costos operativos",
      "metricas_actuales": {
        "rendimiento": "Descripci√≥n de m√©trica con valor actual espec√≠fico (ej: 'Latencia P95: 450ms, objetivo <200ms')",
        "throughput": "Capacidad actual con unidades (ej: '1,500 req/seg, picos de 2,000')",
        "eficiencia": "Uso de recursos con porcentajes (ej: 'CPU al 75% promedio, RAM 80% utilizada')",
        "costo": "Costo operativo mensual (ej: '$12,000/mes en infra cloud')",
        "disponibilidad": "SLA actual y uptime (ej: '99.5% uptime, objetivo 99.9%')"
      },
      "limitaciones_tecnicas": ["Limitaci√≥n 1: constraint espec√≠fico con impacto medible (ej: 'DB single-threaded limita writes a 5k/seg')", "Constraint t√©cnico 2: bottleneck identificado con evidencia", "Limitaci√≥n 3: dependencia legacy que genera fricci√≥n", "Constraint 4: restricci√≥n de infraestructura o presupuesto", "Limitaci√≥n 5: compatibilidad requerida que limita opciones"],
      "objetivos_optimizacion": ["Mejorar latencia P95 en 50% (de 450ms a <225ms)", "Incrementar throughput en 3x (de 1.5k a 4.5k req/seg)", "Reducir costos de infraestructura en 30% ($12k a $8.4k/mes)", "Alcanzar 99.9% uptime (actualmente 99.5%)", "Reducir error rate de 0.5% a <0.1%"],
      "respuesta_esperada": "Propuesta de optimizaci√≥n t√©cnica (m√≠nimo 150 palabras) con arquitectura mejorada detallada, cambios espec√≠ficos propuestos con justificaci√≥n t√©cnica, estimaci√≥n cuantitativa de mejoras esperadas en cada m√©trica, an√°lisis de costo-beneficio, plan de implementaci√≥n por fases, estrategia de testing y rollback, y m√©tricas para validar √©xito",
      "puntos": 10
    }"""
        }
        
        return formatos_casos.get(tipo_caso, formatos_casos["descriptivo"])
    
    def _extraer_preguntas_simple(self, respuesta: str, tipo_esperado: str) -> List[PreguntaExamen]:
        """Extrae preguntas de UN SOLO TIPO sin filtrado complejo
        Usado para generaci√≥n por bloques donde ya sabemos el tipo esperado
        """
        import json
        
        print(f"  üì• Extrayendo preguntas de tipo '{tipo_esperado}'...")
        
        try:
            # Buscar el bloque JSON (objeto o array)
            inicio = respuesta.find('{')
            if inicio == -1:
                inicio = respuesta.find('[')
            
            if inicio == -1:
                print(f"  ‚ùå No se encontr√≥ JSON en la respuesta")
                return []
            
            # Extraer hasta el final balanceado
            nivel = 0
            en_string = False
            escape = False
            fin = inicio
            
            for i in range(inicio, len(respuesta)):
                c = respuesta[i]
                
                if escape:
                    escape = False
                    continue
                
                if c == '\\':
                    escape = True
                    continue
                
                if c == '"':
                    en_string = not en_string
                    continue
                
                if not en_string:
                    if c in '{[':
                        nivel += 1
                    elif c in '}]':
                        nivel -= 1
                        if nivel == 0:
                            fin = i + 1
                            break
            
            json_str = respuesta[inicio:fin]
            
            # Limpiar JSON: eliminar saltos de l√≠nea dentro de strings
            # Esto soluciona cuando el modelo genera JSON con saltos de l√≠nea en opciones
            try:
                # Intentar parsear directamente primero
                datos = json.loads(json_str)
            except json.JSONDecodeError as e:
                print(f"  ‚ö†Ô∏è  Error inicial de JSON: {e}")
                print(f"  üîß Intentando limpiar JSON...")
                
                # Estrategia de limpieza: reemplazar saltos de l√≠nea dentro de strings
                # pero preservar la estructura del JSON
                import re
                
                # Opci√≥n 1: Intentar con json.loads con strict=False
                try:
                    datos = json.loads(json_str, strict=False)
                except:
                    # Opci√≥n 2: Limpiar m√∫ltiples problemas comunes
                    json_limpio = json_str
                    
                    # 1. Limpiar saltos de l√≠nea entre elementos de array
                    # Patr√≥n: "texto",\n      "texto2" ‚Üí "texto", "texto2"
                    json_limpio = re.sub(r'",\s*\n\s*"', '", "', json_limpio)
                    
                    # 2. Limpiar saltos de l√≠nea despu√©s de corchetes de apertura
                    # Patr√≥n: [\n      "texto" ‚Üí ["texto"
                    json_limpio = re.sub(r'\[\s*\n\s*"', '["', json_limpio)
                    
                    # 3. Limpiar saltos de l√≠nea antes de corchetes de cierre
                    # Patr√≥n: "texto"\n      ] ‚Üí "texto"]
                    json_limpio = re.sub(r'"\s*\n\s*\]', '"]', json_limpio)
                    
                    # 4. Normalizar espacios m√∫ltiples
                    json_limpio = re.sub(r'\s+', ' ', json_limpio)
                    
                    try:
                        datos = json.loads(json_limpio)
                        print(f"  ‚úÖ JSON limpiado exitosamente")
                    except Exception as e2:
                        print(f"  ‚ùå Error despu√©s de limpiar: {e2}")
                        print(f"  üìÑ JSON problem√°tico (primeros 500 chars):")
                        print(f"  {json_limpio[:500]}")
                        raise e  # Re-lanzar error original
            
            # Extraer array de preguntas
            lista_preguntas = []
            if isinstance(datos, list):
                lista_preguntas = datos
            elif isinstance(datos, dict):
                if 'preguntas' in datos:
                    lista_preguntas = datos['preguntas']
                elif 'questions' in datos:
                    lista_preguntas = datos['questions']
                elif 'tipo' in datos or 'type' in datos:
                    # Es una pregunta √∫nica
                    lista_preguntas = [datos]
            
            # Convertir a objetos PreguntaExamen
            preguntas = []
            for p in lista_preguntas:
                try:
                    pregunta = PreguntaExamen.from_dict(p)
                    preguntas.append(pregunta)
                except Exception as e:
                    print(f"  ‚ö†Ô∏è Error parseando pregunta: {e}")
                    continue
            
            print(f"  ‚úÖ Extra√≠das {len(preguntas)} preguntas")
            return preguntas
            
        except Exception as e:
            print(f"  ‚ùå Error extrayendo JSON: {e}")
            return []
    
    def _extraer_preguntas(self, respuesta: str, num_preguntas: Dict[str, int] = None) -> List[PreguntaExamen]:
        """Extrae preguntas del JSON"""
        try:
            print(f"\n{'='*60}")
            print(f"üîç EXTRAYENDO JSON DE LA RESPUESTA")
            print(f"{'='*60}")
            
            # Estrategia mejorada para DeepSeek-R1: buscar TODOS los bloques JSON potenciales
            # Buscar todas las apariciones de { que puedan ser inicio de JSON
            posibles_jsons = []
            
            for i, char in enumerate(respuesta):
                if char == '{':
                    # Encontrar el cierre balanceado del JSON desde esta posici√≥n
                    nivel = 0
                    fin = i
                    en_string = False
                    escape = False
                    
                    for j in range(i, len(respuesta)):
                        c = respuesta[j]
                        
                        if escape:
                            escape = False
                            continue
                        
                        if c == '\\':
                            escape = True
                            continue
                        
                        if c == '"':
                            en_string = not en_string
                            continue
                        
                        if not en_string:
                            if c == '{':
                                nivel += 1
                            elif c == '}':
                                nivel -= 1
                                if nivel == 0:
                                    fin = j + 1
                                    json_candidato = respuesta[i:fin]
                                    # Solo considerar JSONs que parezcan razonables (> 50 chars)
                                    if len(json_candidato) > 50:
                                        posibles_jsons.append((i, fin, json_candidato))
                                    break
            
            print(f"üîç Encontrados {len(posibles_jsons)} bloques JSON potenciales")
            
            # Estrategia 1: Buscar JSON completo balanceado
            json_str = None
            inicio = -1
            fin = -1
            
            # Intentar parsear cada JSON candidato, priorizando los m√°s largos
            posibles_jsons.sort(key=lambda x: len(x[2]), reverse=True)
            
            # FASE 1: Buscar JSON con array de preguntas completo
            for idx, (start, end, candidato) in enumerate(posibles_jsons):
                print(f"  üì¶ Candidato {idx+1}: posici√≥n {start}-{end}, tama√±o {len(candidato)} chars")
                print(f"     Inicio: {candidato[:80]}...")
                
                # PRIORIDAD 1: JSON con "preguntas" o "questions" (array completo)
                if '"preguntas"' in candidato or '"questions"' in candidato:
                    # RECHAZAR si contiene placeholders COMO VALORES (no en texto de preguntas)
                    tiene_placeholders = False
                    if ('"puntos": ...' in candidato or 
                        '"puntos":...' in candidato or
                        '"opciones": [...]' in candidato or
                        '"pregunta": "..."' in candidato or
                        '": "..."' in candidato):
                        print(f"     ‚ö†Ô∏è Contiene placeholders COMO VALORES, descartando")
                        tiene_placeholders = True
                    
                    if not tiene_placeholders:
                        print(f"     ‚úÖ Contiene array de preguntas y NO tiene placeholders")
                        json_str = candidato
                        inicio = start
                        fin = end
                        break
                else:
                    print(f"     ‚è≠Ô∏è No contiene array 'preguntas', continuando b√∫squeda...")
            
            # FASE 2: Si no encontr√≥ array completo, buscar preguntas individuales
            if json_str is None:
                print(f"  üí° No se encontr√≥ array completo, buscando preguntas individuales...")
                for idx, (start, end, candidato) in enumerate(posibles_jsons):
                    if '"tipo"' in candidato or '"type"' in candidato:
                        tiene_placeholders = False
                        if ('"puntos": ...' in candidato or 
                            '"puntos":...' in candidato or
                            '"opciones": [...]' in candidato or
                            '"pregunta": "..."' in candidato or
                            '": "..."' in candidato):
                            continue
                        
                        print(f"     ‚úÖ Usando pregunta individual como fallback")
                        json_str = candidato
                        inicio = start
                        fin = end
                        break
            
            if json_str is None and posibles_jsons:
                # Si ninguno tiene campos de pregunta, tomar el m√°s largo
                inicio, fin, json_str = posibles_jsons[0]
                print(f"  üí° Usando JSON m√°s largo como fallback")
            
            if json_str:
                print(f"‚úÖ JSON seleccionado en posici√≥n {inicio}-{fin}")
                print(f"üìÑ JSON extra√≠do (primeros 300 chars):\n{json_str[:300]}...\n")
                
                # Limpiar JSON de errores comunes del modelo
                import re
                
                # 1. Eliminar comas antes de ] o }
                json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)
                
                # 2. Si el JSON termina incompleto, intentar repararlo
                # Buscar campos incompletos tipo: "explanation": "
                json_str = re.sub(r'"\s*:\s*"[^"]*$', '": "Explicaci√≥n no disponible"', json_str)
                
                # 3. Asegurar cierre de objetos y arrays
                # Contar llaves y corchetes abiertos
                count_braces = json_str.count('{') - json_str.count('}')
                count_brackets = json_str.count('[') - json_str.count(']')
                
                # Cerrar los que falten
                if count_braces > 0 or count_brackets > 0:
                    print(f"‚ö†Ô∏è JSON incompleto: {count_braces} llaves, {count_brackets} corchetes sin cerrar")
                    # Cerrar en orden inverso (primero objetos, luego arrays)
                    json_str += '}' * count_braces
                    json_str += ']' * count_brackets
                    print(f"üîß JSON reparado autom√°ticamente")
                
                # Intentar parsear
                try:
                    datos = json.loads(json_str)
                    print(f"‚úÖ JSON parseado correctamente")
                    
                    # Registrar JSON extra√≠do
                    self._agregar_log('json_extraido', json_str)
                    
                    # Verificar estructura - aceptar 'preguntas' o 'questions'
                    campo_preguntas = None
                    if 'preguntas' in datos:
                        campo_preguntas = 'preguntas'
                    elif 'questions' in datos:
                        campo_preguntas = 'questions'
                    
                    if not campo_preguntas:
                        print(f"‚ùå JSON no tiene campo 'preguntas' ni 'questions'")
                        print(f"üìã Campos encontrados: {list(datos.keys())}")
                        
                        # Si el JSON es un array directamente, usarlo
                        if isinstance(datos, list):
                            print(f"üí° El JSON es un array directo con {len(datos)} elementos")
                            campo_preguntas = None
                            lista_preguntas = datos
                        # Si es un objeto con campos de pregunta (type, statement, etc.), es UNA pregunta
                        elif 'type' in datos or 'tipo' in datos:
                            print(f"üí° El JSON es una pregunta √∫nica, convirti√©ndola a array")
                            lista_preguntas = [datos]
                        else:
                            print(f"‚ö†Ô∏è JSON no reconocido, retornando vac√≠o")
                            return []
                    else:
                        lista_preguntas = datos.get(campo_preguntas, [])
                    
                    preguntas = []
                    preguntas_parseadas_log = []
                    for i, p in enumerate(lista_preguntas):
                        try:
                            pregunta = PreguntaExamen.from_dict(p)
                            preguntas.append(pregunta)
                            preguntas_parseadas_log.append(pregunta.to_dict() if hasattr(pregunta, 'to_dict') else str(pregunta))
                            tipo = p.get('tipo') or p.get('type', 'unknown')
                            texto = p.get('pregunta') or p.get('question', '')
                            print(f"‚úÖ Pregunta {i+1}: {tipo} - {texto[:50]}...")
                        except Exception as e:
                            error_msg = f"Error en pregunta {i+1}: {e}"
                            print(f"‚ùå {error_msg}")
                            self._agregar_log('errores', error_msg)
                            continue
                    
                    # Registrar preguntas parseadas
                    self._agregar_log('preguntas_parseadas', preguntas_parseadas_log)
                    
                    print(f"\n‚úÖ Total: {len(preguntas)} preguntas generadas exitosamente")
                    
                    # PASO 1: Eliminar duplicados exactos y similares
                    preguntas_unicas = []
                    textos_vistos = set()
                    
                    def similitud_texto(t1, t2):
                        """Calcula similitud b√°sica entre dos textos"""
                        palabras1 = set(t1.lower().split())
                        palabras2 = set(t2.lower().split())
                        if not palabras1 or not palabras2:
                            return 0
                        interseccion = palabras1.intersection(palabras2)
                        union = palabras1.union(palabras2)
                        return len(interseccion) / len(union)
                    
                    for pregunta in preguntas:
                        texto_normalizado = pregunta.pregunta.strip().lower()
                        
                        # Verificar duplicado exacto
                        if texto_normalizado in textos_vistos:
                            print(f"  üóëÔ∏è  Duplicado exacto: {pregunta.pregunta[:60]}...")
                            continue
                        
                        # Verificar similitud alta (>80%) con preguntas existentes
                        es_similar = False
                        for texto_visto in textos_vistos:
                            if similitud_texto(texto_normalizado, texto_visto) > 0.8:
                                print(f"  üóëÔ∏è  Muy similar: {pregunta.pregunta[:60]}...")
                                es_similar = True
                                break
                        
                        if not es_similar:
                            preguntas_unicas.append(pregunta)
                            textos_vistos.add(texto_normalizado)
                    
                    if len(preguntas_unicas) < len(preguntas):
                        print(f"üßπ Duplicados/similares eliminados: {len(preguntas)} ‚Üí {len(preguntas_unicas)} preguntas √∫nicas")
                    
                    # PASO 2: FILTRAR PREGUNTAS POR TIPO Y CANTIDAD SOLICITADA
                    if num_preguntas and any(v > 0 for v in num_preguntas.values()):
                        preguntas_filtradas = []
                        contador_por_tipo = {}
                        
                        # Mapeo de tipos nuevos a tipos del sistema
                        mapeo_tipos = {
                            'flashcard': 'flashcard',
                            'mcq': 'mcq', 
                            'true_false': 'true_false',
                            'verdadero_falso': 'true_false',
                            'verdadero-falso': 'true_false',
                            'cloze': 'cloze',
                            'short_answer': 'short_answer',
                            'respuesta_corta': 'short_answer',
                            'open_question': 'open_question',
                            'desarrollo': 'open_question',
                            'case_study': 'case_study',
                            'caso_estudio': 'case_study',
                            'reading_comprehension': 'reading_comprehension',
                            'reading_true_false': 'reading_true_false',
                            'reading_cloze': 'reading_cloze',
                            'reading_skill': 'reading_skill',
                            'reading_matching': 'reading_matching',
                            'reading_sequence': 'reading_sequence',
                            'writing_short': 'writing_short',
                            'writing_paraphrase': 'writing_paraphrase',
                            'writing_correction': 'writing_correction',
                            'writing_transformation': 'writing_transformation',
                            'writing_essay': 'writing_essay',
                            'writing_sentence_builder': 'writing_sentence_builder',
                            'writing_picture_description': 'writing_picture_description',
                            'writing_email': 'writing_email',
                            'multiple': 'mcq',
                            'corta': 'short_answer'
                        }
                        
                        for pregunta in preguntas_unicas:
                            # DEBUG: Imprimir tipo exacto de la pregunta
                            print(f"  üîç Pregunta tipo='{pregunta.tipo}' (repr: {repr(pregunta.tipo)})")
                            tipo_normalizado = mapeo_tipos.get(pregunta.tipo, pregunta.tipo)
                            print(f"     ‚Üí Normalizado a: '{tipo_normalizado}'")
                            cantidad_solicitada = num_preguntas.get(tipo_normalizado, 0)
                            print(f"     ‚Üí Cantidad solicitada de '{tipo_normalizado}': {cantidad_solicitada}")
                            
                            # NUEVO: Aceptar preguntas incluso si no se solicitaron expl√≠citamente
                            # siempre que sean de tipos v√°lidos (mcq, true_false, short_answer, etc.)
                            if cantidad_solicitada > 0:
                                if tipo_normalizado not in contador_por_tipo:
                                    contador_por_tipo[tipo_normalizado] = 0
                                
                                if contador_por_tipo[tipo_normalizado] < cantidad_solicitada:
                                    preguntas_filtradas.append(pregunta)
                                    contador_por_tipo[tipo_normalizado] += 1
                                    print(f"     ‚úÖ Aceptada (solicitada)")
                                else:
                                    print(f"     ‚ùå Rechazada (ya se alcanz√≥ el l√≠mite de {cantidad_solicitada})")
                            elif tipo_normalizado in ['mcq', 'true_false', 'short_answer', 'open_question', 'flashcard']:
                                # Tipos v√°lidos aunque no solicitados expl√≠citamente - ACEPTAR
                                if tipo_normalizado not in contador_por_tipo:
                                    contador_por_tipo[tipo_normalizado] = 0
                                preguntas_filtradas.append(pregunta)
                                contador_por_tipo[tipo_normalizado] += 1
                                print(f"     ‚úÖ Aceptada (tipo v√°lido extra)")
                            else:
                                print(f"     ‚ùå Rechazada (tipo no solicitado ni en lista v√°lida)")
                        
                        print(f"üîç Filtrado: {len(preguntas_unicas)} √∫nicas ‚Üí {len(preguntas_filtradas)} solicitadas")
                        print(f"   Solicitadas: {num_preguntas}")
                        print(f"   Filtradas por tipo: {contador_por_tipo}")
                        
                        # Registrar filtrado
                        self._agregar_log('filtrado', {
                            'total_generadas_originales': len(preguntas),
                            'total_unicas': len(preguntas_unicas),
                            'total_filtradas': len(preguntas_filtradas),
                            'solicitadas': num_preguntas,
                            'contador_por_tipo': contador_por_tipo
                        })
                        
                        # Verificar si faltaron preguntas
                        tipos_faltantes = []
                        for tipo, cantidad in num_preguntas.items():
                            generadas = contador_por_tipo.get(tipo, 0)
                            if generadas < cantidad:
                                tipos_faltantes.append(f"{tipo}: {generadas}/{cantidad}")
                        
                        if tipos_faltantes:
                            warning_msg = f"Tipos con menos preguntas generadas: {', '.join(tipos_faltantes)}"
                            self._agregar_log('advertencia', warning_msg)
                            print(f"‚ÑπÔ∏è  INFO: Distribuci√≥n de preguntas generadas:")
                            for faltante in tipos_faltantes:
                                print(f"   üìä {faltante}")
                            print(f"   üí° El examen sigue siendo v√°lido. Si necesitas exactamente la cantidad solicitada, puedes regenerar.")
                        
                        # Registrar resultado final
                        resultado_final = [p.to_dict() if hasattr(p, 'to_dict') else str(p) for p in preguntas_filtradas]
                        self._agregar_log('resultado_final', resultado_final)
                        self._guardar_log()
                        
                        return preguntas_filtradas
                    
                    # Si no hay filtrado, retornar todas las preguntas √∫nicas
                    resultado_final = [p.to_dict() if hasattr(p, 'to_dict') else str(p) for p in preguntas_unicas]
                    self._agregar_log('resultado_final', resultado_final)
                    self._guardar_log()
                    
                    return preguntas_unicas
                    
                except json.JSONDecodeError as e:
                        error_msg = f"Error parseando JSON: {e}"
                        print(f"‚ùå {error_msg}")
                        print(f"üìÑ JSON problem√°tico (primeros 500):\n{json_str[:500]}")
                        print(f"üìÑ √öltimos 200 caracteres:\n{json_str[-200:]}")
                        
                        # INTENTO DE REPARACI√ìN AGRESIVA
                        print(f"\nüîß Intentando reparaci√≥n agresiva del JSON...")
                        
                        # Eliminar texto despu√©s del √∫ltimo } v√°lido
                        ultimo_cierre = json_str.rfind('}')
                        if ultimo_cierre > 0:
                            json_str_cortado = json_str[:ultimo_cierre + 1]
                            
                            # Asegurar que cierra el array de preguntas
                            if '"preguntas"' in json_str_cortado and not json_str_cortado.strip().endswith(']}'):
                                json_str_cortado = json_str_cortado.rstrip() + ']}'
                            
                            try:
                                datos = json.loads(json_str_cortado)
                                print(f"‚úÖ JSON reparado exitosamente cortando al √∫ltimo }}")
                                
                                # Continuar con el procesamiento normal
                                campo_preguntas = None
                                if 'preguntas' in datos:
                                    campo_preguntas = 'preguntas'
                                elif 'questions' in datos:
                                    campo_preguntas = 'questions'
                                
                                if campo_preguntas:
                                    lista_preguntas = datos[campo_preguntas]
                                    if isinstance(lista_preguntas, list):
                                        # Convertir a objetos PreguntaExamen
                                        preguntas = []
                                        preguntas_parseadas_log = []
                                        
                                        for i, pregunta_dict in enumerate(lista_preguntas):
                                            try:
                                                pregunta_obj = PreguntaExamen.from_dict(pregunta_dict)
                                                preguntas.append(pregunta_obj)
                                                print(f"‚úÖ Pregunta {i+1}: {pregunta_obj.tipo} - {pregunta_obj.pregunta[:50]}...")
                                                preguntas_parseadas_log.append(pregunta_obj.to_dict())
                                            except Exception as e:
                                                error_msg = f"Error en pregunta {i+1}: {e}"
                                                print(f"‚ùå {error_msg}")
                                                self._agregar_log('errores', error_msg)
                                                continue
                                        
                                        self._agregar_log('preguntas_parseadas', preguntas_parseadas_log)
                                        print(f"\n‚úÖ Total: {len(preguntas)} preguntas generadas exitosamente")
                                        
                                        # Aplicar filtrado si es necesario
                                        if num_preguntas and any(v > 0 for v in num_preguntas.values()):
                                            preguntas = self._filtrar_preguntas(preguntas, num_preguntas)
                                        
                                        resultado_final = [p.to_dict() if hasattr(p, 'to_dict') else str(p) for p in preguntas]
                                        self._agregar_log('resultado_final', resultado_final)
                                        self._guardar_log()
                                        return preguntas
                            except:
                                pass
                        
                        self._agregar_log('errores', error_msg)
                        self._agregar_log('json_extraido', json_str[:1000])
                        self._guardar_log()
                        return []
            
            # Estrategia 2: Buscar bloques de c√≥digo markdown
            print("‚ö†Ô∏è No se encontr√≥ JSON directo, buscando en bloques markdown...")
            if "```json" in respuesta:
                print("üí° Se detect√≥ bloque ```json```, intentando extraer...")
                inicio_markdown = respuesta.find("```json") + 7
                fin_markdown = respuesta.find("```", inicio_markdown)
                if fin_markdown > inicio_markdown:
                    json_str = respuesta[inicio_markdown:fin_markdown].strip()
                    print(f"‚úÖ JSON encontrado en markdown")
                    try:
                        datos = json.loads(json_str)
                        # Aceptar 'preguntas' o 'questions'
                        lista_preguntas = datos.get('preguntas') or datos.get('questions', [])
                        if isinstance(datos, list):
                            lista_preguntas = datos
                        
                        preguntas = []
                        for p in lista_preguntas:
                            preguntas.append(PreguntaExamen.from_dict(p))
                        print(f"‚úÖ {len(preguntas)} preguntas desde markdown")
                        return preguntas
                    except Exception as e:
                        print(f"‚ùå Error parseando markdown JSON: {e}")
            
            print("‚ùå No se pudo extraer JSON v√°lido de la respuesta")
            error_msg = "No se encontr√≥ JSON v√°lido en la respuesta del modelo"
            self._agregar_log('errores', error_msg)
            self._guardar_log()
            return []
            
        except Exception as e:
            error_msg = f"Error general extrayendo JSON: {e}"
            print(f"‚ùå {error_msg}")
            import traceback
            traceback.print_exc()
            self._agregar_log('errores', error_msg)
            self._guardar_log()
            return []
    
    def evaluar_respuesta(self, pregunta: PreguntaExamen, respuesta_usuario) -> dict:
        """Eval√∫a una respuesta del usuario"""
        resultado = {
            "correcta": False,
            "puntos_obtenidos": 0,
            "feedback": ""
        }
        
        # Convertir lista a string si es necesario
        if isinstance(respuesta_usuario, list):
            respuesta_usuario = respuesta_usuario[0] if respuesta_usuario else ""
        
        # Validar que respuesta_usuario sea string
        if not isinstance(respuesta_usuario, str):
            respuesta_usuario = str(respuesta_usuario)
        
        if not respuesta_usuario or respuesta_usuario.strip() == "":
            resultado["feedback"] = "No se proporcion√≥ respuesta"
            return resultado
        
        respuesta_usuario_lower = respuesta_usuario.strip().lower()
        respuesta_correcta = pregunta.respuesta_correcta
        if respuesta_correcta is None:
            respuesta_correcta = ""
        elif not isinstance(respuesta_correcta, str):
            respuesta_correcta = str(respuesta_correcta)
        respuesta_correcta_lower = respuesta_correcta.strip().lower()
        
        if pregunta.tipo == "multiple" or pregunta.tipo == "mcq":
            # Para m√∫ltiple, solo comparar la letra (A, B, C, D)
            if respuesta_usuario_lower in respuesta_correcta_lower or respuesta_correcta_lower in respuesta_usuario_lower:
                resultado["correcta"] = True
                resultado["puntos_obtenidos"] = pregunta.puntos
                resultado["feedback"] = "¬°Correcto!"
            else:
                resultado["feedback"] = f"Incorrecto. La respuesta correcta es: {pregunta.respuesta_correcta}"
        
        elif pregunta.tipo in ["verdadero_falso", "verdadero-falso", "true_false"]:
            # Extraer respuesta correcta de metadata si existe
            respuesta_correcta_display = pregunta.respuesta_correcta
            if hasattr(pregunta, 'metadata') and pregunta.metadata:
                if isinstance(pregunta.metadata, dict):
                    correct_answer = pregunta.metadata.get('correct_answer')
                    if correct_answer is not None:
                        respuesta_correcta_display = 'Verdadero' if correct_answer else 'Falso'
            
            # Normalizar respuestas para comparaci√≥n flexible
            resp_lower = respuesta_usuario_lower.replace('verdadero', 'true').replace('falso', 'false')
            corr_lower = respuesta_correcta_lower.replace('verdadero', 'true').replace('falso', 'false')
            
            if resp_lower == corr_lower or respuesta_usuario_lower == respuesta_correcta_lower:
                resultado["correcta"] = True
                resultado["puntos_obtenidos"] = pregunta.puntos
                resultado["feedback"] = "¬°Correcto!"
            else:
                resultado["feedback"] = f"Incorrecto. La respuesta correcta es: {respuesta_correcta_display}"
        
        elif pregunta.tipo in ["corta", "desarrollo", "short_answer", "open_question", "case_study",
                               "flashcard", "cloze",
                               "reading_comprehension", "reading_true_false", "reading_cloze", 
                               "reading_skill", "reading_matching", "reading_sequence",
                               "writing_short", "writing_paraphrase", "writing_correction",
                               "writing_transformation", "writing_essay", "writing_sentence_builder",
                               "writing_picture_description", "writing_email"]:
            # Para todos los dem√°s tipos, usar IA para evaluar
            print(f"\nü§ñ Evaluando respuesta de tipo '{pregunta.tipo}' con IA...")
            resultado = self._evaluar_con_ia(pregunta, respuesta_usuario)
        
        else:
            # Tipo desconocido - evaluar con IA por defecto
            print(f"\n‚ö†Ô∏è Tipo de pregunta desconocido: '{pregunta.tipo}' - usando evaluaci√≥n con IA")
            resultado = self._evaluar_con_ia(pregunta, respuesta_usuario)
        
        return resultado
    
    def _evaluar_con_ia(self, pregunta: PreguntaExamen, respuesta_usuario: str) -> dict:
        """Eval√∫a una respuesta de desarrollo/corta usando IA"""
        
        # ========== EVALUACI√ìN ESPECIAL PARA CLOZE ==========
        if pregunta.tipo == 'cloze' and hasattr(pregunta, 'metadata') and pregunta.metadata:
            if isinstance(pregunta.metadata, dict) and 'answers' in pregunta.metadata:
                respuestas_correctas = pregunta.metadata['answers']
                
                # Dividir respuestas del usuario (pueden estar separadas por comas o |||)
                respuestas_usuario_lista = []
                if ', ' in respuesta_usuario:
                    respuestas_usuario_lista = [r.strip() for r in respuesta_usuario.split(',')]
                elif '|||' in respuesta_usuario:
                    respuestas_usuario_lista = [r.strip() for r in respuesta_usuario.split('|||')]
                else:
                    respuestas_usuario_lista = [respuesta_usuario.strip()]
                
                # Comparar cada respuesta
                correctas = 0
                total = len(respuestas_correctas)
                conceptos_correctos = []
                conceptos_faltantes = []
                
                for i, respuesta_correcta in enumerate(respuestas_correctas):
                    if i < len(respuestas_usuario_lista):
                        resp_usuario = respuestas_usuario_lista[i].lower().strip()
                        resp_correcta = str(respuesta_correcta).lower().strip()
                        
                        # Comparaci√≥n flexible (permite variaciones)
                        if resp_usuario == resp_correcta or resp_usuario in resp_correcta or resp_correcta in resp_usuario:
                            correctas += 1
                            conceptos_correctos.append(respuesta_correcta)
                        else:
                            # Verificar similitud b√°sica (al menos 60% de las palabras coinciden)
                            palabras_correcta = set(resp_correcta.split())
                            palabras_usuario = set(resp_usuario.split())
                            if palabras_usuario and palabras_correcta:
                                coincidencia = len(palabras_usuario.intersection(palabras_correcta)) / len(palabras_correcta)
                                if coincidencia >= 0.6:
                                    correctas += 1
                                    conceptos_correctos.append(respuesta_correcta)
                                else:
                                    conceptos_faltantes.append(respuesta_correcta)
                            else:
                                conceptos_faltantes.append(respuesta_correcta)
                    else:
                        conceptos_faltantes.append(respuesta_correcta)
                
                # Calcular puntos
                porcentaje = correctas / total if total > 0 else 0
                puntos = round(porcentaje * pregunta.puntos, 1)
                
                return {
                    "correcta": porcentaje >= 0.6,
                    "puntos_obtenidos": puntos,
                    "conceptos_correctos": conceptos_correctos,
                    "conceptos_faltantes": conceptos_faltantes,
                    "feedback": f"Completaste {correctas}/{total} huecos correctamente ({int(porcentaje*100)}%)."
                }
        
        # ========== EVALUACI√ìN NORMAL PARA OTROS TIPOS ==========
        
        # Extraer respuesta correcta dependiendo del tipo
        respuesta_modelo = pregunta.respuesta_correcta
        
        # Para flashcards, extraer de metadata.solution.answer
        if pregunta.tipo == 'flashcard' and hasattr(pregunta, 'metadata') and pregunta.metadata:
            if isinstance(pregunta.metadata, dict):
                solution = pregunta.metadata.get('solution', {})
                if isinstance(solution, dict):
                    respuesta_modelo = solution.get('answer', respuesta_modelo)
        
        # Para casos de estudio, extraer de metadata (respuesta_esperada o sample_answer)
        elif pregunta.tipo == 'case_study' and hasattr(pregunta, 'metadata') and pregunta.metadata:
            if isinstance(pregunta.metadata, dict):
                # Intentar primero respuesta_esperada, luego sample_answer
                respuesta_modelo = pregunta.metadata.get('respuesta_esperada') or pregunta.metadata.get('sample_answer', respuesta_modelo)
        
        # Si es un diccionario (fallback), extraer el campo 'answer'
        if isinstance(respuesta_modelo, dict):
            respuesta_modelo = respuesta_modelo.get('answer', str(respuesta_modelo))
        
        # Convertir a string si no lo es
        if not isinstance(respuesta_modelo, str):
            respuesta_modelo = str(respuesta_modelo)
        
        # Si a√∫n es None o vac√≠o, usar un placeholder
        if not respuesta_modelo or respuesta_modelo == 'None':
            respuesta_modelo = "No hay respuesta modelo definida para esta pregunta"
        
        prompt = f"""Tarea: Comparaci√≥n de texto y extracci√≥n de conceptos clave.

TEXTO DE REFERENCIA:
"{respuesta_modelo}"

TEXTO A COMPARAR:
"{respuesta_usuario}"

INSTRUCCIONES DE PROCESAMIENTO:
1. Extraer t√©rminos y conceptos importantes del texto de referencia
2. Verificar presencia de cada t√©rmino/concepto en el texto a comparar
3. Calcular puntuaci√≥n: (conceptos_presentes / total_conceptos) * {pregunta.puntos}

OUTPUT REQUERIDO - JSON √∫nicamente:
{{
  "puntos": <float entre 0 y {pregunta.puntos}>,
  "conceptos_correctos": [<lista de t√©rminos encontrados>],
  "conceptos_faltantes": [<lista de t√©rminos ausentes>],
  "feedback": "<resumen de coincidencias>"
}}

CONTEXTO DE LA PREGUNTA: {pregunta.pregunta}

Genera el JSON ahora:"""

        try:
            if self.usar_ollama:
                # Evaluar con Ollama
                response = requests.post(
                    "http://localhost:11434/api/generate",
                    json={
                        "model": self.modelo_ollama,
                        "prompt": prompt,
                        "stream": False,
                        "options": {
                            "temperature": 0.3,  # M√°s determin√≠stico
                            "num_predict": 400   # M√°s tokens para retroalimentaci√≥n detallada
                        }
                    },
                    timeout=60
                )
                
                if response.status_code == 200:
                    respuesta_ia = response.json()['response']
                    print(f"üìù Respuesta IA (primeros 300 chars): {respuesta_ia[:300]}")
                    
                    # Detectar rechazo del modelo con m√°s patrones
                    rechazos = [
                        'lo siento', 'no puedo', 'cannot', "can't", 'disculpa', 'sorry',
                        'no pueda', 'unable to', 'cannot fulfill', 'no cumplir',
                        'esa solicitud', 'that request', 'contenido pol√≠tico', 'political content',
                        'evaluar el trabajo', 'generar respuestas que', 'no puedo generar'
                    ]
                    if any(rechazo in respuesta_ia.lower() for rechazo in rechazos):
                        print(f"‚ö†Ô∏è Modelo rechaz√≥ evaluar - usando evaluaci√≥n por similitud de texto")
                        # Calcular similitud mejorada
                        texto_modelo = respuesta_modelo.lower()
                        texto_usuario = respuesta_usuario.lower()
                        
                        # Extraer palabras significativas (m√°s de 3 letras)
                        palabras_modelo = set(p for p in texto_modelo.split() if len(p) > 3)
                        palabras_usuario = set(p for p in texto_usuario.split() if len(p) > 3)
                        
                        coincidencias = palabras_modelo.intersection(palabras_usuario)
                        
                        # Calcular porcentaje basado en palabras clave
                        if len(palabras_modelo) > 0:
                            porcentaje = len(coincidencias) / len(palabras_modelo)
                        else:
                            porcentaje = 0
                        
                        puntos = round(porcentaje * pregunta.puntos, 1)
                        
                        return {
                            "correcta": puntos >= pregunta.puntos * 0.6,
                            "puntos_obtenidos": puntos,
                            "conceptos_correctos": list(coincidencias)[:8],
                            "conceptos_faltantes": list(palabras_modelo - palabras_usuario)[:5],
                            "feedback": f"Evaluaci√≥n autom√°tica: {puntos}/{pregunta.puntos} puntos basado en similitud de conceptos."
                        }
                    
                    # Extraer JSON balanceado
                    inicio = respuesta_ia.find('{')
                    if inicio >= 0:
                        nivel = 0
                        fin = inicio
                        en_string = False
                        escape = False
                        
                        for i in range(inicio, len(respuesta_ia)):
                            char = respuesta_ia[i]
                            
                            if escape:
                                escape = False
                                continue
                            
                            if char == '\\':
                                escape = True
                                continue
                            
                            if char == '"':
                                en_string = not en_string
                                continue
                            
                            if not en_string:
                                if char == '{':
                                    nivel += 1
                                elif char == '}':
                                    nivel -= 1
                                    if nivel == 0:
                                        fin = i + 1
                                        break
                        
                        if fin > inicio:
                            json_str = respuesta_ia[inicio:fin]
                            evaluacion = json.loads(json_str)
                            
                            puntos = float(evaluacion.get('puntos', 0))
                            conceptos_correctos = evaluacion.get('conceptos_correctos', [])
                            conceptos_faltantes = evaluacion.get('conceptos_faltantes', [])
                            feedback_base = evaluacion.get('feedback', 'Sin evaluaci√≥n')
                            
                            # Construir feedback detallado
                            feedback = feedback_base
                            if conceptos_correctos:
                                feedback += f"\\n\\n‚úÖ Conceptos que dominas: {', '.join(conceptos_correctos)}"
                            if conceptos_faltantes:
                                feedback += f"\\n\\n‚ùå Conceptos que te faltan comprender: {', '.join(conceptos_faltantes)}"
                            
                            print(f"‚úÖ Evaluaci√≥n: {puntos}/{pregunta.puntos} puntos")
                            print(f"‚úÖ Conceptos correctos: {conceptos_correctos}")
                            print(f"‚ùå Conceptos faltantes: {conceptos_faltantes}")
                            
                            return {
                                "correcta": puntos >= pregunta.puntos * 0.6,  # 60% o m√°s es correcto
                                "puntos_obtenidos": puntos,
                                "feedback": feedback,
                                "conceptos_correctos": conceptos_correctos,
                                "conceptos_faltantes": conceptos_faltantes
                            }
            
            # Fallback: evaluaci√≥n simple por palabras clave
            print("‚ö†Ô∏è Usando evaluaci√≥n fallback")
            
            # Extraer texto de respuesta correcta (puede ser dict en flashcards)
            respuesta_modelo = pregunta.respuesta_correcta
            if isinstance(respuesta_modelo, dict):
                respuesta_modelo = respuesta_modelo.get('answer', str(respuesta_modelo))
            if not isinstance(respuesta_modelo, str):
                respuesta_modelo = str(respuesta_modelo)
            
            palabras_correctas = set(respuesta_modelo.lower().split())
            palabras_usuario = set(respuesta_usuario.lower().split())
            coincidencias = len(palabras_correctas.intersection(palabras_usuario))
            similitud = coincidencias / len(palabras_correctas) if palabras_correctas else 0
            
            puntos = pregunta.puntos * similitud
            
            if similitud >= 0.7:
                feedback = "¬°Excelente! Respuesta muy completa."
            elif similitud >= 0.5:
                feedback = "Bien, pero podr√≠as agregar m√°s detalles."
            elif similitud >= 0.3:
                feedback = "Parcialmente correcto, faltan conceptos clave."
            else:
                feedback = f"Incompleto. Respuesta esperada: {respuesta_modelo}"
            
            return {
                "correcta": similitud >= 0.6,
                "puntos_obtenidos": round(puntos, 1),
                "feedback": feedback
            }
            
        except Exception as e:
            print(f"‚ùå Error evaluando con IA: {e}")
            import traceback
            traceback.print_exc()
            
            # Extraer respuesta modelo para fallback
            respuesta_modelo = pregunta.respuesta_correcta
            if isinstance(respuesta_modelo, dict):
                respuesta_modelo = respuesta_modelo.get('answer', 'No disponible')
            if not isinstance(respuesta_modelo, str):
                respuesta_modelo = str(respuesta_modelo)
            
            # Fallback
            return {
                "correcta": False,
                "puntos_obtenidos": 0,
                "feedback": f"Error en evaluaci√≥n. Respuesta esperada: {respuesta_modelo}"
            }


# Funci√≥n de utilidad para verificar qu√© usar
def detectar_backend_disponible():
    """Detecta qu√© backend est√° disponible"""
    # Verificar Ollama
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=2)
        if response.status_code == 200:
            modelos = response.json().get('models', [])
            if modelos:
                print("‚úÖ Ollama disponible con GPU autom√°tica")
                return "ollama", modelos[0]['name']
    except:
        pass
    
    # Verificar llama-cpp-python
    try:
        from llama_cpp import Llama
        print("‚úÖ llama-cpp-python disponible")
        return "gguf", None
    except:
        pass
    
    print("‚ö†Ô∏è No hay backend disponible")
    return None, None


if __name__ == "__main__":
    # Test
    print("üß™ Test de GeneradorUnificado\n")
    
    backend, modelo = detectar_backend_disponible()
    
    if backend == "ollama":
        print(f"\nüì¶ Usando Ollama con {modelo}")
        generador = GeneradorUnificado(usar_ollama=True, modelo_ollama=modelo)
    else:
        print("\nüì¶ Usando llama-cpp-python")
        generador = GeneradorUnificado(usar_ollama=False, modelo_path_gguf="modelos/tu_modelo.gguf")
    
    contenido = """
    Python es un lenguaje de programaci√≥n interpretado de alto nivel.
    Fue creado por Guido van Rossum en 1991.
    """
    
    preguntas = generador.generar_examen(
        contenido,
        {'multiple': 2, 'verdadero_falso': 1}
    )
    
    print(f"\nüìù Preguntas generadas: {len(preguntas)}")
